<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Bui Huu Dai">
<meta name="dcterms.date" content="2024-07-04">

<title>First Step in AI – Bui Huu Dai</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../Github_bird.png" rel="icon" type="image/png">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-2fef5ea3f8957b3e4ecc936fc74692ca.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-8e47eaf163dee9e5ea02780d02199294.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-bca7bfc09c99158c9822bef989cf6fc8.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-8e47eaf163dee9e5ea02780d02199294.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-6JR4N915S6"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-6JR4N915S6', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="First Step in AI – Bui Huu Dai">
<meta property="og:description" content="Dai’s blog.">
<meta property="og:image" content="https://bhdai.github.io/blog/posts/2024-06-30-your-deep-learning-journey/xkcd.png">
<meta property="og:site_name" content="Bui Huu Dai">
<meta property="og:image:height" content="843">
<meta property="og:image:width" content="953">
<meta name="twitter:title" content="First Step in AI – Bui Huu Dai">
<meta name="twitter:description" content="Dai’s blog.">
<meta name="twitter:image" content="https://bhdai.github.io/blog/posts/2024-06-30-your-deep-learning-journey/xkcd.png">
<meta name="twitter:image-height" content="843">
<meta name="twitter:image-width" content="953">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const queryPrefersDark = window.matchMedia('(prefers-color-scheme: dark)');
    const darkModeDefault = queryPrefersDark.matches;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    queryPrefersDark.addEventListener("change", e => {
      if(window.localStorage.getItem("quarto-color-scheme") !== null)
        return;
      const alternate = e.matches
      toggleColorMode(alternate);
      localAlternateSentinel = e.matches ? 'alternate' : 'default'; // this is used alongside local storage!
      toggleGiscusIfUsed(alternate, darkModeDefault);
    });
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bui Huu Dai</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/bhdai"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/daibui1234"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">First Step in AI</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">blogging</div>
                <div class="quarto-category">fastai</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Bui Huu Dai </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 4, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#the-xkcd-joke-and-debunking-deep-learning-myths" id="toc-the-xkcd-joke-and-debunking-deep-learning-myths" class="nav-link" data-scroll-target="#the-xkcd-joke-and-debunking-deep-learning-myths">The XKCD Joke and Debunking Deep Learning Myths</a></li>
  <li><a href="#top-down-learning-approach" id="toc-top-down-learning-approach" class="nav-link" data-scroll-target="#top-down-learning-approach">Top-Down Learning Approach</a></li>
  <li><a href="#understanding-deep-learning" id="toc-understanding-deep-learning" class="nav-link" data-scroll-target="#understanding-deep-learning">Understanding Deep learning</a></li>
  <li><a href="#a-brief-history-of-deep-learning" id="toc-a-brief-history-of-deep-learning" class="nav-link" data-scroll-target="#a-brief-history-of-deep-learning">A Brief History of Deep Learning</a></li>
  <li><a href="#the-sofware-pytorch-fastai-and-jupyter" id="toc-the-sofware-pytorch-fastai-and-jupyter" class="nav-link" data-scroll-target="#the-sofware-pytorch-fastai-and-jupyter">The Sofware: Pytorch, Fastai, and Jupyter</a></li>
  <li><a href="#exploring-the-is-it-a-bird-classifier" id="toc-exploring-the-is-it-a-bird-classifier" class="nav-link" data-scroll-target="#exploring-the-is-it-a-bird-classifier">Exploring the “Is it a Bird?” Classifier</a>
  <ul class="collapse">
  <li><a href="#searching-for-images-duckduckgo-search" id="toc-searching-for-images-duckduckgo-search" class="nav-link" data-scroll-target="#searching-for-images-duckduckgo-search">Searching for images: DuckDuckGo Search</a></li>
  <li><a href="#downloading-and-preparing-images" id="toc-downloading-and-preparing-images" class="nav-link" data-scroll-target="#downloading-and-preparing-images">Downloading and Preparing Images</a></li>
  <li><a href="#verifying-and-leaning-images" id="toc-verifying-and-leaning-images" class="nav-link" data-scroll-target="#verifying-and-leaning-images">Verifying and Leaning Images</a></li>
  <li><a href="#the-datablock-api" id="toc-the-datablock-api" class="nav-link" data-scroll-target="#the-datablock-api">The DataBlock API</a></li>
  <li><a href="#training-the-model-welcome-to-the-learner-world" id="toc-training-the-model-welcome-to-the-learner-world" class="nav-link" data-scroll-target="#training-the-model-welcome-to-the-learner-world">Training the Model: Welcome to the Learner World</a></li>
  <li><a href="#making-predictions" id="toc-making-predictions" class="nav-link" data-scroll-target="#making-predictions">Making Predictions</a></li>
  </ul></li>
  <li><a href="#what-is-machine-learning" id="toc-what-is-machine-learning" class="nav-link" data-scroll-target="#what-is-machine-learning">What Is Machine Learning</a>
  <ul class="collapse">
  <li><a href="#traditional-programming" id="toc-traditional-programming" class="nav-link" data-scroll-target="#traditional-programming">Traditional Programming</a></li>
  <li><a href="#program-using-weight-and-assignment" id="toc-program-using-weight-and-assignment" class="nav-link" data-scroll-target="#program-using-weight-and-assignment">Program Using Weight And Assignment</a></li>
  <li><a href="#training-a-machine-learning-model" id="toc-training-a-machine-learning-model" class="nav-link" data-scroll-target="#training-a-machine-learning-model">Training a Machine Learning Model</a></li>
  <li><a href="#using-a-trained-model" id="toc-using-a-trained-model" class="nav-link" data-scroll-target="#using-a-trained-model">Using a Trained Model</a></li>
  </ul></li>
  <li><a href="#what-our-image-recognizer-learned" id="toc-what-our-image-recognizer-learned" class="nav-link" data-scroll-target="#what-our-image-recognizer-learned">What Our Image Recognizer Learned</a></li>
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"></a>
  <ul class="collapse">
  <li><a href="#beyond-image-classification-other-application-of-deep-learning" id="toc-beyond-image-classification-other-application-of-deep-learning" class="nav-link" data-scroll-target="#beyond-image-classification-other-application-of-deep-learning">Beyond Image Classification: Other Application of Deep Learning</a></li>
  <li><a href="#the-important-of-validation-and-test-sets" id="toc-the-important-of-validation-and-test-sets" class="nav-link" data-scroll-target="#the-important-of-validation-and-test-sets">The Important of Validation and Test Sets</a>
  <ul class="collapse">
  <li><a href="#why-do-we-need-a-validation-set" id="toc-why-do-we-need-a-validation-set" class="nav-link" data-scroll-target="#why-do-we-need-a-validation-set">Why Do We Need a Validation set?</a></li>
  <li><a href="#preventing-overfitting-with-a-test-set" id="toc-preventing-overfitting-with-a-test-set" class="nav-link" data-scroll-target="#preventing-overfitting-with-a-test-set">Preventing Overfitting with a Test set</a></li>
  </ul></li>
  <li><a href="#wrapping-up" id="toc-wrapping-up" class="nav-link" data-scroll-target="#wrapping-up">Wrapping Up</a></li>
  <li><a href="#final-thoughts" id="toc-final-thoughts" class="nav-link" data-scroll-target="#final-thoughts">Final Thoughts</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/bhdai/blog/blob/main/posts/2024-06-30-your-deep-learning-journey/index.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bhdai/blog/blob/main/posts/2024-06-30-your-deep-learning-journey/index.ipynb" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/bhdai/blog/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">






<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Welcome to my deep dive in to the world of deep learning! In this blog post, I’ll be sharing my journey through <a href="https://course.fast.ai/Lessons/lesson1.html">the first lesson</a> of fast.ai course an acclaimed program that makes learning AI accessible and enjoyable.</p>
<p>Fast.ai was created with the goal of making deep learning understandable for everyone, no matter their background, and Lesson 1 accomplishes that by having us build a simple yet fascinating model: a bird classifier. This exciting task not just introduces me to the basics of deep learning but also allow me to experience firsthand the power and simplicity of modern AI tools.</p>
<p>Join me as I walk you though key concept covered in the Lesson 1, from understanding how images are processed by computers to training and validating our model. I will also share some personal insights and reflections on the learning process, aiming to make this technical journey both informative and relatable.</p>
<p>Whether you are a beginner in AI or someone looking for refresh your knowledge, I hope this post inspires and guides you in your own deep learning</p>
</section>
<section id="the-xkcd-joke-and-debunking-deep-learning-myths" class="level2">
<h2 class="anchored" data-anchor-id="the-xkcd-joke-and-debunking-deep-learning-myths">The XKCD Joke and Debunking Deep Learning Myths</h2>
<style>
    figure {
        display: block;
        margin-left: auto;
        margin-right: auto;
        text-align: center;
    }
</style>
<figure class="figure">
<img src="./xkcd.png" alt="XKCD joke" style="width:50%;" class="figure-img">
<figcaption>
XKCD Joke
</figcaption>
</figure>
<p>Jeremy Howard kicked off the lesson with relatable XKCD Joke about how in 2015, detecting a bird in a photo was seen as a challenging task, almost a joke. Fast forward to today, and we can build such as system in mere minutes, showcasing how far deep learning has come.</p>
<p>Many people believe that diving into deep learning requires extensive mathematical knowledge, huge datasets, and expensive hardware. However, these myths are far from the truth.</p>
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 66%">
</colgroup>
<thead>
<tr class="header">
<th>Myth(Don’t need)</th>
<th>Truth</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Lots of math</td>
<td>Just high school math is sufficient</td>
</tr>
<tr class="even">
<td>Lots of data</td>
<td>We’ve seen record-breaking results with fewer than 50 items of data</td>
</tr>
<tr class="odd">
<td>Lots of expensive computer</td>
<td>You can perform state-of-the-art work with hardware available for free of minimal cost</td>
</tr>
</tbody>
</table>
</section>
<section id="top-down-learning-approach" class="level2">
<h2 class="anchored" data-anchor-id="top-down-learning-approach">Top-Down Learning Approach</h2>
<p>One of the most refreshing aspects of fastai course is its top-down teaching approach. Traditional education often starts with the basics and slowly builds up to more complex topics. However, Jeremy Howard and Rachel Thomas believe that learning is more effective when you see the big picture first.</p>
<p>In the fastai course, we start by building practically applications from lesson one, allowing us to see immediate results and understanding the relevance of what we are doing. This approach mirrors how we learn many real-word skills, such as sport or cooking, where we start by trying out the activity and learn the details as needed.</p>
<p>By diving straight into creating a deep learning model, we get hands-on experience early on, which helps solidify our understanding and maintain our interest. As we process though the course, we gradually delve deeper into the underlying principles and theories, building a robust foundation along the way</p>
</section>
<section id="understanding-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="understanding-deep-learning">Understanding Deep learning</h2>
<p>Deep learning is a technique for extracting and transforming data, with application ranging from speech recognition to image classification. It uses multiple layer of neural networks, where each layer refines the data received from the previous one. These layers are trained using the algorithms that minimize the errors and improve accuracy, enabling the network to learn specific tasks.</p>
<p>Deep learning’s power, flexibility, and simplicity make it applicable across various field, including social science, medicine, finance, and more. For instance, despite lacking of medical background, Jeremy Howard founded <a href="">Enlitic</a>, a company leveraging deep learning to diagnose illnesses. Within months, their algorithm was more effective at identifying malignant tumors than radiologists.</p>
<p>Here are some areas where deep learning excels:</p>
<ul>
<li><strong>Natural Language Processing (NLP)</strong>: Answering question, speech recognition, document summarization, and more.</li>
<li><strong>Computer Vision</strong>: Interpreting satellite images, face recognition, and autonomous vehicle navigation.</li>
<li><strong>Medicine</strong>: Analyzing radiology images, measuring features and medical scans, and diagnosing diseases.</li>
<li><strong>Biology</strong>: Protein folding, genomics tasks, and cell classification.</li>
<li><strong>Image Generation</strong>: Colorizing images, enhancing resolution, and converting images to artistic style.</li>
<li><strong>Recommendation System</strong>: Web search optimization, product recommendations, and personalized content layout.</li>
<li><strong>Gaming</strong>: Mastering games like Chess, Go, and various video games.</li>
<li><strong>Robotics</strong>: Handling challenging objects and complex manipulation tasks.</li>
<li><strong>Other</strong>: Financial forecasting, text-to-speech conversion, and much more.</li>
</ul>
<p>The versatility of deep learning lies in its foundation: neuron networks.</p>
</section>
<section id="a-brief-history-of-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="a-brief-history-of-deep-learning">A Brief History of Deep Learning</h2>
<style>
    figure {
        display: block;
        mergin-left: auto;
        mergin-right: auto;
        text-align: center;
    }
</style>
<figure class="figure">
<img src="./neurral_net.png" alt="Biological Neurons vs. Artificial Neural Network" style="width:50%;" class="figure-img">
<figcaption>
Biological Neurons vs.&nbsp;Artificial Neural Network
</figcaption>
</figure>
<p>Deep learning draws inspiration from human brain’s neural network. The concept of neural network isn’t new; it dates back to 1957 with the creation of the first neural network. The fundamental ideas remain the same today, but advances in hardware and data availability have significantly propelled the field forward.</p>
</section>
<section id="the-sofware-pytorch-fastai-and-jupyter" class="level2">
<h2 class="anchored" data-anchor-id="the-sofware-pytorch-fastai-and-jupyter">The Sofware: Pytorch, Fastai, and Jupyter</h2>
<p>At fastai, after extensive testing of various machine learning packages and languages, they decided to adopt Pytorch in 2017 for their course, software development, and research. Pytorch has become the fastest-growing deep learning library and is widely used in academic research and industry. Its flexibility and expressiveness make it an excellent foundation for deep learning.</p>
<p>The fastai library builds on top of Pytorch, provide high-level functionality for deep learning. This layered architecture allows for a seamless learning experience, make it easier to understand both high-level concepts and low-level operations.</p>
<p>However, the specific software you use a less important than understanding the core principles and techniques of deep learning. Learning to transition between the libraries is relatively quick, but mastering deep learning foundation is crucial.</p>
<p>Jupyter notebook, a powerful and reflexible tool for data science, will be our primary platform for experimentation. Its interaction with fastai and Pytorch makes it ideal for developing and testing deep learning model.</p>
<p>Ready to see it in action? Let’s train our first model!</p>
</section>
<section id="exploring-the-is-it-a-bird-classifier" class="level2">
<h2 class="anchored" data-anchor-id="exploring-the-is-it-a-bird-classifier">Exploring the “Is it a Bird?” Classifier</h2>
<p>One of the most exciting part of Lesson 1 was building our own image classifier to determine whether the given image contains a bird. For this project, we used the fastai library along with pre-trained model to quickly and efficiently create our classifier. Let’s dive into the code walkthrough.</p>
<p>The basic steps we’ll need to do:</p>
<ol type="1">
<li>Use DuckDuckGo for search images of “bird photos”</li>
<li>Use DuckDuckGo to search for images of “forest photos”</li>
<li>Fine-tune a pre-trained neural network to recognize these two groups</li>
<li>Try running this model on a picture of bird and see if it works.</li>
</ol>
<section id="searching-for-images-duckduckgo-search" class="level3">
<h3 class="anchored" data-anchor-id="searching-for-images-duckduckgo-search">Searching for images: DuckDuckGo Search</h3>
<p>Instead of using a big search that requires an API key, we opted to DuckDuckGo, which doesn’t require an API key for image searches. This make the setup simpler and faster.</p>
<p>But make sure you run this command in your terminal before run the code to update DuckDuckGo</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-Uqq</span> fastai duckduckgo_search</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="cell-9" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> duckduckgo_search <span class="im">import</span> DDGS</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastcore.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>ddgs <span class="op">=</span> DDGS()</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> search_images(term, max_images<span class="op">=</span><span class="dv">30</span>):</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Searching for '</span><span class="sc">{</span>term<span class="sc">}</span><span class="ss">'"</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> L(ddgs.images(keywords<span class="op">=</span>term, max_results<span class="op">=</span>max_images)).itemgot(<span class="st">'image'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-10" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>urls <span class="op">=</span> search_images(<span class="st">'bird photos'</span>, max_images<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>urls[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Searching for 'bird photos'</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>'https://images.pexels.com/photos/326900/pexels-photo-326900.jpeg?cs=srgb&amp;dl=wood-flight-bird-326900.jpg&amp;fm=jpg'</code></pre>
</div>
</div>
<p>Jeremy Howard mentioned that using <code>import *</code> in Jupyter notebooks is not the big deal because Jupyter only import what we use. This approach simplifies the code and keeps it clean.</p>
<p>Here’s the quick explanation of the functions and libraries used in this snippet:</p>
<p><code>DDGS</code> from <code>duckduckgo_search</code>:</p>
<ul>
<li><code>duckduckgo_search</code>: This library allows us to search for images using DuckDuckGo without the need for an API key. So no more begging Google for an API key.</li>
<li><code>DDGS</code>: The class that does the heavy lifting of searching for images.</li>
</ul>
<p><code>fastcore</code>: - <code>fastcore</code>: A foundational library that make Python feel like a Lamborghini-sleek, powerful, and fast.</p>
<p><code>L</code>:</p>
<ul>
<li><code>L</code>: A magical list from <code>fastcore</code> that does way more than the regular Python list. Think of it as a list on steroids.</li>
</ul>
<p>In our example, <code>search_images</code> is a function that performs an image search using DuckDuckGo. It’s print out the search term being used and return a list of images URLs retrieved from the search results.</p>
<p>for more details on the tools, you can refer to the <a href="https://fastcore.fast.ai/">fastcore documentation</a> and the <a href="https://pypi.org/project/duckduckgo-search/">duckduckgo_search documentation</a>.</p>
<div id="cell-12" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastdownload <span class="im">import</span> download_url</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>dest <span class="op">=</span> <span class="st">'bird.jpg'</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>download_url(urls[<span class="dv">0</span>], dest, show_progress<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>im <span class="op">=</span> Image.<span class="bu">open</span>(dest)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>im.to_thumb(<span class="dv">256</span>,<span class="dv">256</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-13" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>download_url(search_images(<span class="st">'forest photos'</span>, max_images<span class="op">=</span><span class="dv">1</span>)[<span class="dv">0</span>], <span class="st">'forest.jpg'</span>, show_progress<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>Image.<span class="bu">open</span>(<span class="st">'forest.jpg'</span>).to_thumb(<span class="dv">256</span>,<span class="dv">256</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Searching for 'forest photos'</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-5-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p><code>fastdownload</code> and <code>download_url</code>:</p>
<ul>
<li><code>fastdownload</code>: Think of this as your friendly neighborhood delivery service, but for files. It’s help with downloading files and datasets easier.</li>
<li><code>download_url</code>: A function that fetches the file you need from a URL. In our case, it says “Hey URL, gimme that picture!” and save it as <code>bird.png</code></li>
</ul>
<p><code>fastai.vision.all</code>:</p>
<ul>
<li>This module from the fastai library is like a Swiss Army knife for vision tasks, providing all the tools you need, from data loaders to model training utilities.</li>
</ul>
<p><code>to_thumb</code>: - A method from the <code>PIL.Image</code> class, which is quite handy it resizes an image to a thumbnail while maintaining the aspect ratio. Kind of like shrinking your favorite sweater but in a good way</p>
<p>These libraries and function streamline the process of getting and preparing the images for our model. For more detailed documentation, you can refer to the <a href="https://fastdownload.fast.ai/">fastdownload</a>, <a href="https://docs.fast.ai/tutorial.vision.html">fastai vision</a>, and <a href="https://pillow.readthedocs.io/en/stable/">Pillow</a> documentation.</p>
</section>
<section id="downloading-and-preparing-images" class="level3">
<h3 class="anchored" data-anchor-id="downloading-and-preparing-images">Downloading and Preparing Images</h3>
<p>To build our dataset, we need to download images for the categories we are interested in (‘forest’ and ‘bird’). Here’s how we did it:</p>
<div id="cell-16" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>searches <span class="op">=</span> <span class="st">'forest'</span>,<span class="st">'bird'</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path(<span class="st">'bird_or_not'</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> sleep</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> o <span class="kw">in</span> searches:</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    dest <span class="op">=</span> (path<span class="op">/</span>o)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    dest.mkdir(exist_ok<span class="op">=</span><span class="va">True</span>, parents<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    download_images(dest, urls<span class="op">=</span>search_images(<span class="ss">f'</span><span class="sc">{</span>o<span class="sc">}</span><span class="ss"> photo'</span>))</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    sleep(<span class="dv">10</span>)  <span class="co"># Pause between searches to avoid over-loading server</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    download_images(dest, urls<span class="op">=</span>search_images(<span class="ss">f'</span><span class="sc">{</span>o<span class="sc">}</span><span class="ss"> sun photo'</span>))</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    sleep(<span class="dv">10</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    download_images(dest, urls<span class="op">=</span>search_images(<span class="ss">f'</span><span class="sc">{</span>o<span class="sc">}</span><span class="ss"> shade photo'</span>))</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    sleep(<span class="dv">10</span>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    resize_images(path<span class="op">/</span>o, max_size<span class="op">=</span><span class="dv">400</span>, dest<span class="op">=</span>path<span class="op">/</span>o)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Searching for 'forest photo'
Searching for 'forest sun photo'
Searching for 'forest shade photo'
Searching for 'bird photo'
Searching for 'bird sun photo'
Searching for 'bird shade photo'</code></pre>
</div>
</div>
<p><code>Path</code>:</p>
<ul>
<li><code>Path</code>: An object-oriented way to work with filesystem paths. It makes handling files and directories as easy as pie.</li>
</ul>
<p><code>download_images</code>:</p>
<ul>
<li><code>download_images</code>: This function fetches a bunch of images from the internet and saves them in a specified directory. Like ordering a pizza, but instead of pizza, you get pictures.</li>
</ul>
<p><em>Pausing Between Searches</em>:</p>
<ul>
<li>Pausing between searches (<code>sleep(10)</code>) is important to avoid overloading the server. Think of it as giving the server a coffee break between each request.</li>
</ul>
<p><code>resize_images</code>:</p>
<ul>
<li><code>resize_images</code>: A function from fastai that resizes images to a maximum specified size. This is useful for ensuring all images are of a consistent size before training the model.</li>
</ul>
<p>For more details on these tools, you can refer to the <a href="https://docs.python.org/3/library/pathlib.html">pathlib</a>, <a href="https://docs.fast.ai/vision.utils.html">Vision utils</a> documentation.</p>
</section>
<section id="verifying-and-leaning-images" class="level3">
<h3 class="anchored" data-anchor-id="verifying-and-leaning-images">Verifying and Leaning Images</h3>
<p>After download images, it’s essential to verify them and remove corrupt or invalid images.</p>
<div id="cell-19" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>failed <span class="op">=</span> verify_images(get_image_files(path))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>failed.<span class="bu">map</span>(Path.unlink)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(failed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>0</code></pre>
</div>
</div>
<p><code>verify_images</code>:</p>
<ul>
<li><code>verify_images</code>: Think of this as the bouncer for your image dataset, checking IDs to make sure no bad images get through.</li>
</ul>
<p><code>get_image_file</code>:</p>
<ul>
<li><code>get_image_file</code>: This function grabs all image paths in a directory. It’s like having someone fetch all your misplaced socks in the laundry room.</li>
</ul>
<p><code>Path.unlink</code>:</p>
<ul>
<li><code>Path.unlink</code>: A method to delete files. This is how we get rid of the bad apples in the bunch.</li>
</ul>
<p>Fortunately, in my case, all downloaded images were valid, so <code>len(failed)</code> return <code>0</code>–no bad apples in our dataset!</p>
</section>
<section id="the-datablock-api" class="level3">
<h3 class="anchored" data-anchor-id="the-datablock-api">The DataBlock API</h3>
<p>Creating our data loader is a critical step. The <code>DataBlock</code> API in fastai allows us to define how to transform and manage our data easily.</p>
<div id="cell-22" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> DataBlock(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    blocks<span class="op">=</span>(ImageBlock, CategoryBlock), </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    get_items<span class="op">=</span>get_image_files, </span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    splitter<span class="op">=</span>RandomSplitter(valid_pct<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    get_y<span class="op">=</span>parent_label,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    item_tfms<span class="op">=</span>[Resize(<span class="dv">192</span>, method<span class="op">=</span><span class="st">'squish'</span>)]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>).dataloaders(path, bs<span class="op">=</span><span class="dv">32</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>dls.show_batch(max_n<span class="op">=</span><span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here’s the breakdown of the arguments in <code>DataBlock</code>:</p>
<p><code>blocks</code>:</p>
<ul>
<li>Specifies the type of inputs and targets. In our case, we have images (<code>ImageBlock</code>) and categories (<code>CategoryBlock</code>). It’s like saying, “I have pictures of cats and dogs”</li>
</ul>
<p><code>get_items</code>:</p>
<ul>
<li>Function to get the list of items. Here we’re using <code>get_image_file</code> to retrieve all our image files.</li>
</ul>
<p><code>splitter</code>:</p>
<ul>
<li>Defines how to split the dataset into training and validation sets. <code>RandomSplitter(valid_pct=0.2, seed=42)</code> means 20% of the data will be used for validation. The <code>seed</code> ensures that every time we run the code we get the same split. Think of like setting your DVR to record your favorite show at the same time every week.</li>
</ul>
<p><code>get_y</code>:</p>
<ul>
<li>Function to get the target label from each item. We use <code>parent_label</code> to get the label from parent directory name (e.g., ‘forest’ or ‘bird’)</li>
</ul>
<p><code>item_tfms</code>:</p>
<ul>
<li>item transformation to apply. We use <code>Resize(129, method='squish')</code> to resize images to 129x129 pixels by squishing them if necessary.</li>
</ul>
<p><code>dataloaders</code>:</p>
<ul>
<li>Creates the data loaders for our dataset, with a batch size of 32. Data loaders are like conveyor belt that feed the data into your model in manageable chunks.</li>
</ul>
<p>The <code>show_batch</code> method is handy way to visualize a batch of data items. It’s like a quick preview to make sure everything looks good.</p>
<p>For more details, checkout the fastai <a href="https://docs.fast.ai/data.block.html">DataBlock API documentation</a>.</p>
</section>
<section id="training-the-model-welcome-to-the-learner-world" class="level3">
<h3 class="anchored" data-anchor-id="training-the-model-welcome-to-the-learner-world">Training the Model: Welcome to the Learner World</h3>
<p>After preparing our dataset, it’s time to train our model. We use the <code>vision_learner</code> function to setup a learner and the powerful <code>fine_tune</code> method to train the model.</p>
<div id="cell-25" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet18, metrics<span class="op">=</span>error_rate)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
  0%|          | 0.00/44.7M [00:00&lt;?, ?B/s]100%|██████████| 44.7M/44.7M [00:00&lt;00:00, 145MB/s] </code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.120399</td>
<td>1.209828</td>
<td>0.411765</td>
<td>00:01</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.185352</td>
<td>0.054729</td>
<td>0.029412</td>
<td>00:01</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.102830</td>
<td>0.023147</td>
<td>0.000000</td>
<td>00:01</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.072183</td>
<td>0.049310</td>
<td>0.029412</td>
<td>00:01</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><code>vision_learner</code>:</p>
<ul>
<li>This create a learner object that combines our data loaders(<code>dls</code>) and a pre-trained model(<code>resnet18</code>). We basically saying, “Hey, take this data and use this model to learn from it.”</li>
</ul>
<p><code>resnet18</code>:</p>
<ul>
<li>A specific architecture of a Convolutional Neuron Network that’s been pre-trained on a large dataset. Think of it as seasoned detective who’s seen it all and just need to be briefed on this specific case.</li>
</ul>
<p><code>metrics=error_rate</code>:</p>
<ul>
<li>This specifies that we want to use the error rate as a metric to evaluate our model’s performance. It’s like having a scoreboard to keep track of who’s winning.<br>
</li>
</ul>
<p><code>fine_tune(3)</code>:</p>
<ul>
<li>Here’s where the magic happens. Unlike the traditional <code>fit</code> method, <code>fine_tune</code> starts by refining the pre-trained model with our specific data. It’s like taking your detective and train them on a nuances of this particular mystery. The <code>3</code> indicates the number of epochs (full cycles through the training data).</li>
</ul>
<p>The <code>fine_tune</code> method is particularly powerful because it starts with a model that already knows a lot (thanks to pre-training) and fine-tune it to specific task. This approach often yields better results, faster and with less data, compared to training a model from scratch.</p>
</section>
<section id="making-predictions" class="level3">
<h3 class="anchored" data-anchor-id="making-predictions">Making Predictions</h3>
<p>Finally, let’s make our bird classifier predict whether or not an image contain a bird.</p>
<div id="cell-28" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>is_bird,_,probs <span class="op">=</span> learn.predict(PILImage.create(<span class="st">'bird.jpg'</span>))</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"This is a: </span><span class="sc">{</span>is_bird<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Probability it's a bird: </span><span class="sc">{</span>probs[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-stdout">
<pre><code>This is a: bird.
Probability it's a bird: 0.9988</code></pre>
</div>
</div>
<p><code>PILImage.create</code>:</p>
<ul>
<li>This function create a image object from a file. It’s like saying “Hey, look at this picture I just took.”</li>
</ul>
<p><code>learn.predict</code>:</p>
<ul>
<li><p>This method uses our train model to predict what’s in a image. It’s like asking your well-trained detective, “What do you see in this picture?”</p></li>
<li><p>The method returns three values:</p>
<ul>
<li><code>is_bird</code>: The predicted label(whether it’s a bird or not).</li>
<li><code>probs</code>: The probabilities associated with each class.</li>
</ul></li>
</ul>
<p>When we print out the predicted label and the probability. If the model says it’s a bird with a high probability, you can feel pretty confident your model knows its bird!</p>
<p>Building the “Is it a Bird?” classifier was hands-on way to introduce the principles of deep learning. By leveraging fastai and Pytorch, we could quickly create an effective model with minimal code. This approach of starting with practical, top-down learning ensures that we see immediately results and understand the real world applicability of deep learning from the get-go.</p>
</section>
</section>
<section id="what-is-machine-learning" class="level2">
<h2 class="anchored" data-anchor-id="what-is-machine-learning">What Is Machine Learning</h2>
<p>Ah, the age-old question: What is the machine learning? Well, imagine if your computer was a child, and you were its teacher. Instead of giving it a strict set of rules to follow(which, let’s be honest, kids hate), you give it examples from which it can learn. In essence, machine learning is about enabling computer to learn from data rather than being explicitly programmed. It’s like teaching your computer how to ride a bike by letting it practice, fall and get up again, rather than reading it a manual</p>
<p>Let’s take a closer look at this with a series of visualizations:</p>
<section id="traditional-programming" class="level3">
<h3 class="anchored" data-anchor-id="traditional-programming">Traditional Programming</h3>
<p>In traditional Programming we write explicit instructions-a program-that processes input to produce results.</p>
<div class="cell" data-fig-width="6" data-fig-height="1" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="576" height="96" viewbox="0.00 0.00 293.79 58.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 54)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-54 289.79,-54 289.79,4 -4,4"></polygon>
<!-- program -->
<g id="node1" class="node">
<title>program</title>
<polygon fill="none" stroke="black" points="177.29,-50 109.29,-50 105.29,-46 105.29,0 173.29,0 177.29,-4 177.29,-50"></polygon>
<polyline fill="none" stroke="black" points="173.29,-46 105.29,-46 "></polyline>
<polyline fill="none" stroke="black" points="173.29,-46 173.29,0 "></polyline>
<polyline fill="none" stroke="black" points="173.29,-46 177.29,-50 "></polyline>
<text text-anchor="middle" x="141.29" y="-20.8" font-family="Times,serif" font-size="14.00">program</text>
</g>
<!-- results -->
<g id="node3" class="node">
<title>results</title>
<ellipse fill="none" stroke="black" cx="249.54" cy="-25" rx="36.5" ry="18"></ellipse>
<text text-anchor="middle" x="249.54" y="-20.8" font-family="Times,serif" font-size="14.00">results</text>
</g>
<!-- program&#45;&gt;results -->
<g id="edge2" class="edge">
<title>program-&gt;results</title>
<path fill="none" stroke="black" d="M177.38,-25C185.54,-25 194.35,-25 202.9,-25"></path>
<polygon fill="black" stroke="black" points="203.13,-28.5 213.13,-25 203.13,-21.5 203.13,-28.5"></polygon>
</g>
<!-- inputs -->
<g id="node2" class="node">
<title>inputs</title>
<ellipse fill="none" stroke="black" cx="34.65" cy="-25" rx="34.79" ry="18"></ellipse>
<text text-anchor="middle" x="34.65" y="-20.8" font-family="Times,serif" font-size="14.00">inputs</text>
</g>
<!-- inputs&#45;&gt;program -->
<g id="edge1" class="edge">
<title>inputs-&gt;program</title>
<path fill="none" stroke="black" d="M69.33,-25C77.58,-25 86.53,-25 95.22,-25"></path>
<polygon fill="black" stroke="black" points="95.23,-28.5 105.23,-25 95.23,-21.5 95.23,-28.5"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Think of it as following a recipe step-by-step: preheat the oven, mix the ingredients, bake for 30 minutes, and voilà, you have a cake.</p>
</section>
<section id="program-using-weight-and-assignment" class="level3">
<h3 class="anchored" data-anchor-id="program-using-weight-and-assignment">Program Using Weight And Assignment</h3>
<p>In machine learning, we use model with weights(parameters) that processes inputs to generates result.</p>
<div class="cell" data-fig-width="5.5" data-fig-height="2" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="528" height="192" viewbox="0.00 0.00 306.65 98.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 94)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-94 302.65,-94 302.65,4 -4,4"></polygon>
<!-- model -->
<g id="node1" class="node">
<title>model</title>
<polygon fill="none" stroke="black" points="190.16,-70 122.16,-70 118.16,-66 118.16,-20 186.16,-20 190.16,-24 190.16,-70"></polygon>
<polyline fill="none" stroke="black" points="186.16,-66 118.16,-66 "></polyline>
<polyline fill="none" stroke="black" points="186.16,-66 186.16,-20 "></polyline>
<polyline fill="none" stroke="black" points="186.16,-66 190.16,-70 "></polyline>
<text text-anchor="middle" x="154.16" y="-40.8" font-family="Times,serif" font-size="14.00">model</text>
</g>
<!-- results -->
<g id="node3" class="node">
<title>results</title>
<ellipse fill="none" stroke="black" cx="262.4" cy="-45" rx="36.5" ry="18"></ellipse>
<text text-anchor="middle" x="262.4" y="-40.8" font-family="Times,serif" font-size="14.00">results</text>
</g>
<!-- model&#45;&gt;results -->
<g id="edge2" class="edge">
<title>model-&gt;results</title>
<path fill="none" stroke="black" d="M190.24,-45C198.4,-45 207.21,-45 215.76,-45"></path>
<polygon fill="black" stroke="black" points="215.99,-48.5 225.99,-45 215.99,-41.5 215.99,-48.5"></polygon>
</g>
<!-- inputs -->
<g id="node2" class="node">
<title>inputs</title>
<ellipse fill="none" stroke="black" cx="41.08" cy="-72" rx="34.79" ry="18"></ellipse>
<text text-anchor="middle" x="41.08" y="-67.8" font-family="Times,serif" font-size="14.00">inputs</text>
</g>
<!-- inputs&#45;&gt;model -->
<g id="edge1" class="edge">
<title>inputs-&gt;model</title>
<path fill="none" stroke="black" d="M72.72,-64.55C83.66,-61.89 96.22,-58.84 108.12,-55.95"></path>
<polygon fill="black" stroke="black" points="109.01,-59.33 117.9,-53.57 107.36,-52.53 109.01,-59.33"></polygon>
</g>
<!-- weights -->
<g id="node4" class="node">
<title>weights</title>
<ellipse fill="none" stroke="black" cx="41.08" cy="-18" rx="41.16" ry="18"></ellipse>
<text text-anchor="middle" x="41.08" y="-13.8" font-family="Times,serif" font-size="14.00">weights</text>
</g>
<!-- weights&#45;&gt;model -->
<g id="edge3" class="edge">
<title>weights-&gt;model</title>
<path fill="none" stroke="black" d="M77.53,-26.62C87.24,-28.98 97.9,-31.57 108.08,-34.04"></path>
<polygon fill="black" stroke="black" points="107.5,-37.5 118.04,-36.46 109.15,-30.7 107.5,-37.5"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Here, the model is like a reflexible recipe that can adjust itself. The ingredients(inputs) are mixed differently depending on the weights, and the output is a delicious result that varies based on those adjustments.</p>
</section>
<section id="training-a-machine-learning-model" class="level3">
<h3 class="anchored" data-anchor-id="training-a-machine-learning-model">Training a Machine Learning Model</h3>
<p>Training a model involves feeding inputs through the model to produce results, measuring performance and updating the weights to improve accuracy.</p>
<div class="cell" data-fig-width="6.3" data-fig-height="2" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="605" height="192" viewbox="0.00 0.00 501.62 98.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 94)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-94 497.62,-94 497.62,4 -4,4"></polygon>
<!-- model -->
<g id="node1" class="node">
<title>model</title>
<polygon fill="none" stroke="black" points="191.16,-78 123.16,-78 119.16,-74 119.16,-28 187.16,-28 191.16,-32 191.16,-78"></polygon>
<polyline fill="none" stroke="black" points="187.16,-74 119.16,-74 "></polyline>
<polyline fill="none" stroke="black" points="187.16,-74 187.16,-28 "></polyline>
<polyline fill="none" stroke="black" points="187.16,-74 191.16,-78 "></polyline>
<text text-anchor="middle" x="155.16" y="-48.8" font-family="Times,serif" font-size="14.00">model</text>
</g>
<!-- results -->
<g id="node3" class="node">
<title>results</title>
<ellipse fill="none" stroke="black" cx="300.72" cy="-53" rx="36.5" ry="18"></ellipse>
<text text-anchor="middle" x="300.72" y="-48.8" font-family="Times,serif" font-size="14.00">results</text>
</g>
<!-- model&#45;&gt;results -->
<g id="edge2" class="edge">
<title>model-&gt;results</title>
<path fill="none" stroke="black" d="M191.28,-53C210.31,-53 234.04,-53 254.45,-53"></path>
<polygon fill="black" stroke="black" points="254.47,-56.5 264.47,-53 254.47,-49.5 254.47,-56.5"></polygon>
</g>
<!-- inputs -->
<g id="node2" class="node">
<title>inputs</title>
<ellipse fill="none" stroke="black" cx="41.08" cy="-72" rx="34.79" ry="18"></ellipse>
<text text-anchor="middle" x="41.08" y="-67.8" font-family="Times,serif" font-size="14.00">inputs</text>
</g>
<!-- inputs&#45;&gt;model -->
<g id="edge1" class="edge">
<title>inputs-&gt;model</title>
<path fill="none" stroke="black" d="M74.19,-66.56C85,-64.72 97.27,-62.64 108.89,-60.67"></path>
<polygon fill="black" stroke="black" points="109.62,-64.1 118.89,-58.98 108.45,-57.2 109.62,-64.1"></polygon>
</g>
<!-- performance -->
<g id="node5" class="node">
<title>performance</title>
<ellipse fill="none" stroke="black" cx="433.8" cy="-53" rx="59.65" ry="18"></ellipse>
<text text-anchor="middle" x="433.8" y="-48.8" font-family="Times,serif" font-size="14.00">performance</text>
</g>
<!-- results&#45;&gt;performance -->
<g id="edge4" class="edge">
<title>results-&gt;performance</title>
<path fill="none" stroke="black" d="M337.19,-53C345.4,-53 354.41,-53 363.52,-53"></path>
<polygon fill="black" stroke="black" points="363.81,-56.5 373.81,-53 363.81,-49.5 363.81,-56.5"></polygon>
</g>
<!-- weights -->
<g id="node4" class="node">
<title>weights</title>
<ellipse fill="none" stroke="black" cx="41.08" cy="-18" rx="41.16" ry="18"></ellipse>
<text text-anchor="middle" x="41.08" y="-13.8" font-family="Times,serif" font-size="14.00">weights</text>
</g>
<!-- weights&#45;&gt;model -->
<g id="edge3" class="edge">
<title>weights-&gt;model</title>
<path fill="none" stroke="black" d="M75.1,-28.31C85.79,-31.65 97.83,-35.41 109.23,-38.97"></path>
<polygon fill="black" stroke="black" points="108.44,-42.39 119.03,-42.03 110.53,-35.71 108.44,-42.39"></polygon>
</g>
<!-- performance&#45;&gt;weights -->
<g id="edge5" class="edge">
<title>performance-&gt;weights</title>
<path fill="none" stroke="black" d="M393.16,-39.65C376.07,-34.47 355.74,-29.05 336.97,-26 251.85,-12.15 151.12,-13.06 92.14,-15.3"></path>
<polygon fill="black" stroke="black" points="91.83,-11.81 81.98,-15.72 92.12,-18.81 91.83,-11.81"></polygon>
<text text-anchor="middle" x="227.81" y="-21.2" font-family="Times,serif" font-size="14.00">update</text>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Think of it as trial and error. The model tries to bake a cake, and if it’s to salty, it adjusts the recipe (update the weights). Over time, it learns the perfect proportions.</p>
</section>
<section id="using-a-trained-model" class="level3">
<h3 class="anchored" data-anchor-id="using-a-trained-model">Using a Trained Model</h3>
<p>Once the model is trained, it can be used just like a traditional program, taking inputs and producing results predictably.</p>
<div class="cell" data-fig-width="5" data-fig-height="1" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<svg width="480" height="96" viewbox="0.00 0.00 293.79 58.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" style="; max-width: none; max-height: none">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 54)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-54 289.79,-54 289.79,4 -4,4"></polygon>
<!-- model -->
<g id="node1" class="node">
<title>model</title>
<polygon fill="none" stroke="black" points="177.29,-50 109.29,-50 105.29,-46 105.29,0 173.29,0 177.29,-4 177.29,-50"></polygon>
<polyline fill="none" stroke="black" points="173.29,-46 105.29,-46 "></polyline>
<polyline fill="none" stroke="black" points="173.29,-46 173.29,0 "></polyline>
<polyline fill="none" stroke="black" points="173.29,-46 177.29,-50 "></polyline>
<text text-anchor="middle" x="141.29" y="-20.8" font-family="Times,serif" font-size="14.00">model</text>
</g>
<!-- results -->
<g id="node3" class="node">
<title>results</title>
<ellipse fill="none" stroke="black" cx="249.54" cy="-25" rx="36.5" ry="18"></ellipse>
<text text-anchor="middle" x="249.54" y="-20.8" font-family="Times,serif" font-size="14.00">results</text>
</g>
<!-- model&#45;&gt;results -->
<g id="edge2" class="edge">
<title>model-&gt;results</title>
<path fill="none" stroke="black" d="M177.38,-25C185.54,-25 194.35,-25 202.9,-25"></path>
<polygon fill="black" stroke="black" points="203.13,-28.5 213.13,-25 203.13,-21.5 203.13,-28.5"></polygon>
</g>
<!-- inputs -->
<g id="node2" class="node">
<title>inputs</title>
<ellipse fill="none" stroke="black" cx="34.65" cy="-25" rx="34.79" ry="18"></ellipse>
<text text-anchor="middle" x="34.65" y="-20.8" font-family="Times,serif" font-size="14.00">inputs</text>
</g>
<!-- inputs&#45;&gt;model -->
<g id="edge1" class="edge">
<title>inputs-&gt;model</title>
<path fill="none" stroke="black" d="M69.33,-25C77.58,-25 86.53,-25 95.22,-25"></path>
<polygon fill="black" stroke="black" points="95.23,-28.5 105.23,-25 95.23,-21.5 95.23,-28.5"></polygon>
</g>
</g>
</svg>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Now, you have reliable recipe that consistently makes the perfect cake. The model processes new inputs(ingredients) and produces outputs(cakes) with the learned adjustments.</p>
</section>
</section>
<section id="what-our-image-recognizer-learned" class="level2">
<h2 class="anchored" data-anchor-id="what-our-image-recognizer-learned">What Our Image Recognizer Learned</h2>
<p>At this stage, we have an image recognizer that works very well. But what is it actually doing? Although many people believe that deep learning results in impenetrable “black box” models (where predictions are given, but no one understand why), this isn’t entirely true. There is a vast body of research showing how to inspect deep learning model deeply and gain rich insights for them. However, all kind of machine learning model (including machine learning and traditional statistical models) can be challenging to fully understand, especially when dealing with new data that differs significantly from the training data.</p>
<p>When we fine-tuned our pre-trained model, we adapted the last layers(originally trained on general features like flowers, humans, animals) to specialize in a birds versus non-birds problem. Imagine our model initially knew how to recognize the entire zoo, but now we’ve trained it to focus solely on recognizing birds. More generally, we could specialize such a pre-trained model on many different tasks.</p>
</section>
<section id="section" class="level1">
<h1></h1>
<section id="beyond-image-classification-other-application-of-deep-learning" class="level2">
<h2 class="anchored" data-anchor-id="beyond-image-classification-other-application-of-deep-learning">Beyond Image Classification: Other Application of Deep Learning</h2>
<p>Deep learning isn’t just about figuring out whether there’s bird in your photo. It’s way more powerful than that! Let’s explore a couple of areas where deep learning make significant strides:</p>
<ol type="1">
<li><p><strong>Image Segmentation</strong>:</p>
<p>Segmentation is a process of identifying and labeling pixels in an image belonging to the same object. This is critically important for application like autonomous vehicles where the car needs to recognize and localize object such as pedestrians, other vehicles, and road signs. Instead of just saying, “Hey, there’s a cat in a picture”, segmentation says, “Here’s the outline of the cat in this picture”.</p></li>
<li><p><strong>Natural Language Processing (NLP)</strong>: Deep learning has dramatically improved Natural Language Processing over the last few years. Now computers can:</p>
<ul>
<li><strong>Generate text</strong>: Write coherent and context-aware essays (but don’t trust them with your love letters just yet).</li>
<li><strong>Translate languages</strong>: Turn English into Spanish, French, or Klingon (okay, maybe not Klingon…yet)</li>
<li><strong>Analyze comments</strong>: Understand sentiments, detect sarcasm, and probably tell when you’re being a bit snarky.</li>
<li><strong>Label words in sentences</strong>: Identify parts of speech (nouns, verbs, adjectives, etc.), entities (like names and places), and more.</li>
</ul></li>
</ol>
<p>Here’s some cool code to classify the sentiment of a movie review better than anything available just a few years ago:</p>
<div id="cell-46" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.text.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid<span class="op">=</span><span class="st">'test'</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> text_classifier_learner(dls, AWD_LSTM, drop_mult<span class="op">=</span><span class="fl">0.5</span>, metrics<span class="op">=</span>accuracy)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">4</span>, <span class="fl">1e-2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="144441344" class="" max="144440600" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [144441344/144440600 00:03&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="105070592" class="" max="105067061" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [105070592/105067061 00:01&lt;00:00]
    </div>
    
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.462561</td>
<td>0.395122</td>
<td>0.822320</td>
<td>03:08</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">accuracy</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.301779</td>
<td>0.248262</td>
<td>0.899480</td>
<td>06:38</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.244484</td>
<td>0.202708</td>
<td>0.921480</td>
<td>06:38</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.189148</td>
<td>0.194167</td>
<td>0.926160</td>
<td>06:37</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.148741</td>
<td>0.191470</td>
<td>0.929720</td>
<td>06:38</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="cell-47" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>learn.predict(<span class="st">"I really liked that movie!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>('pos', tensor(1), tensor([7.8042e-04, 9.9922e-01]))</code></pre>
</div>
</div>
<p>And boom! You have a state-of-art sentiment analyzer.</p>
</section>
<section id="the-important-of-validation-and-test-sets" class="level2">
<h2 class="anchored" data-anchor-id="the-important-of-validation-and-test-sets">The Important of Validation and Test Sets</h2>
<p>We’ve trained our model and it’s looking pretty smart, but know how do we know it’s actually learned something useful? This is where validation and test sets come in.</p>
<section id="why-do-we-need-a-validation-set" class="level3">
<h3 class="anchored" data-anchor-id="why-do-we-need-a-validation-set">Why Do We Need a Validation set?</h3>
<p>The goal of a model is to make predictions about unseen data. If we trained a model with all our data and evaluated it using the same data, we wouldn’t really know how well it performs on new, unseen data. It could just memorize the training data(cheating basically). The model could get great results on your training data but bomb when given the data to analyze. To avoid this, we: - <strong>We split dataset</strong>: We divide our data into training and validation sets. The training set is used to teach the model, and the validation set is used to see how well it’s learning</p>
</section>
<section id="preventing-overfitting-with-a-test-set" class="level3">
<h3 class="anchored" data-anchor-id="preventing-overfitting-with-a-test-set">Preventing Overfitting with a Test set</h3>
<p>Overfitting is a common issue where the model preform exceptionally well on the training set but poorly on the validation set, meaning it has memorized the training data rather than learning the generalizable pattern.</p>
<p>Even when your model hasn’t fully memorized all your data, it might memorized certain parts of it during earlier training stages. The longer you train, the better the accuracy on the training set, but eventually, the validation accuracy will start to decline. This is because your model is begins memorizing the training data instead of learning the pattern that generalize well. When this happens, we say the model is overfitting.</p>
<p>Here’s an example to visualize overfitting:</p>
<style>
    figure {
        display: block;
        mergin-left: auto;
        mergin-right: auto;
        text-align: center;
    }
</style>
<figure class="figure">
<img src="./att_00000.png" alt="Example of overfitting" style="width:90%;" class="figure-img">
<figcaption>
Example of overfitting
</figcaption>
</figure>
<p>The Image shows what happens when you overfit, using a simplified example where we have just one parameter and some randomly generated data. Although the overfitted model’s prediction are accurate for the data near the observed data points, they are way off when outside of that range.</p>
<p>Overfitting is the single most important and challenging issue when training machine learning models. It’s easy to create a model that does the great job at making predictions on the data it’s been trained on, but making accurate predictions on new data is much harder.</p>
<p>For instance, if you writing a handwritten digit classifier (as we will very soon) and use it to recognize numbers on checks, you won’t see the same numbers the model was trained on–checks will have different variations of handwriting to deal with.</p>
</section>
</section>
<section id="wrapping-up" class="level2">
<h2 class="anchored" data-anchor-id="wrapping-up">Wrapping Up</h2>
<p>Deep learning is an exciting field that extends far beyond simple image classification. From understand speech to translate languages and detecting malware, it’s applications are vast. Through this blog post, we’ve seen how to build a bird classifier using the fastai library-an accessible, powerful tool that simplifies the complexities of machine learning.</p>
<p>By splitting our data into training and validation sets, we ensure our model doesn’t cheat and genuinely learns the task at hand. With powerful tools like fastai and the ability to handle the diverse tasks, deep learning truly has potential to transform numerous industries.</p>
<p>I hope you enjoyed this journey as much as I did. Remember, the key to mastering deep learning is to keep experimenting and learning. So go ahead, build that next big thing, and maybe teach your computer to recognize your pet fish or translate cat’s meows!</p>
</section>
<section id="final-thoughts" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts">Final Thoughts</h2>
<p>Thank you for joining me on this deep learning adventure! If you find this blog helpful or inspiring, please share it with others who might also be interested. Deep learning is a continuously evolving field with endless possibilities. Stay curious, keep learning, and don’t hesitate to dive deeper into the world of AI.</p>
<p>Feel free to leave your comments, questions, or insights below. I’d love to hear your experiences, projects, and what you’re learning. Together, we can continue to explore and push the boundaries of what’s possible with deep learning.</p>
<p>Happy coding, and may your models always be accurate!</p>


</section>
</section>

</main> <!-- /main -->
<script type="text/javascript">
// Enhance theme switching experience
document.addEventListener('DOMContentLoaded', function() {
  // Add smooth transitions to all elements when theme changes
  const style = document.createElement('style');
  style.textContent = `
* {
transition: background-color 0.3s ease, color 0.3s ease, border-color 0.3s ease !important;
}

.navbar, .card, .table, .btn {
transition: all 0.3s ease !important;
}
`;
  document.head.appendChild(style);

  // Enhance code copy functionality
  const codeBlocks = document.querySelectorAll('pre code');
  codeBlocks.forEach(function(codeBlock) {
    codeBlock.parentElement.style.position = 'relative';
  });

  // Add fade-in animation for post listings
  const posts = document.querySelectorAll('.post-listing .card');
  posts.forEach(function(post, index) {
    post.style.opacity = '0';
    post.style.transform = 'translateY(20px)';
    setTimeout(() => {
      post.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
      post.style.opacity = '1';
      post.style.transform = 'translateY(0)';
    }, index * 100);
  });

  // Smooth scroll for anchor links
  document.querySelectorAll('a[href^="#"]').forEach(anchor => {
    anchor.addEventListener('click', function (e) {
      e.preventDefault();
      const target = document.querySelector(this.getAttribute('href'));
      if (target) {
        target.scrollIntoView({
          behavior: 'smooth',
          block: 'start'
        });
      }
    });
  });

  // Enhanced table styling
  const tables = document.querySelectorAll('table');
  tables.forEach(function(table) {
    if (!table.classList.contains('table')) {
      table.classList.add('table', 'table-striped');
    }

    // Wrap tables in responsive container
    if (!table.parentElement.classList.contains('table-responsive')) {
      const wrapper = document.createElement('div');
      wrapper.classList.add('table-responsive');
      table.parentNode.insertBefore(wrapper, table);
      wrapper.appendChild(table);
    }
  });

  // Replace keyboard shortcuts on non-Mac platforms
  const kPlatformMac = typeof navigator !== 'undefined' ? /Mac/.test(navigator.platform) : false;
  if (!kPlatformMac) {
    var kbds = document.querySelectorAll("kbd");
    kbds.forEach(function(kbd) {
      kbd.innerHTML = kbd.innerHTML.replace(/⌘/g, '⌃');
    });
  }

  // Add reading progress indicator
  function addReadingProgress() {
    const article = document.querySelector('main article, main .content, .post-content');
    if (article) {
      const progressBar = document.createElement('div');
      progressBar.style.cssText = `
position: fixed;
top: 0;
left: 0;
width: 0%;
height: 3px;
background: var(--bs-primary);
z-index: 1000;
transition: width 0.3s ease;
`;
      document.body.appendChild(progressBar);

      window.addEventListener('scroll', function() {
        const scrolled = window.scrollY;
        const height = article.offsetHeight - window.innerHeight;
        const progress = Math.min(scrolled / height * 100, 100);
        progressBar.style.width = progress + '%';
      });
    }
  }

  // Only add reading progress on individual blog posts
  if (document.querySelector('.post-title') || document.querySelector('article')) {
    addReadingProgress();
  }
});

// Theme preference detection and saving
(function() {
  // Save theme preference to localStorage
  const themeToggle = document.querySelector('[data-bs-toggle="color-scheme"]');
  if (themeToggle) {
    themeToggle.addEventListener('click', function() {
      setTimeout(() => {
        const currentTheme = document.documentElement.getAttribute('data-bs-theme');
        localStorage.setItem('quarto-color-scheme', currentTheme);
      }, 100);
    });
  }

  // Load saved theme preference
  const savedTheme = localStorage.getItem('quarto-color-scheme');
  if (savedTheme) {
    document.documentElement.setAttribute('data-bs-theme', savedTheme);
  }
})();
</script>

<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/bhdai\.github\.io\/blog\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<input type="hidden" id="giscus-base-theme" value="preferred_color_scheme">
<input type="hidden" id="giscus-alt-theme" value="preferred_color_scheme">
<script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      if (authorPrefersDark) {
          [baseTheme, altTheme] = [altTheme, baseTheme];
      }
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "bhdai/blog";
    script.dataset.repoId = "R_kgDOMP9wjw";
    script.dataset.category = "Blog";
    script.dataset.categoryId = "DIC_kwDOMP9wj84Cs7wf";
    script.dataset.mapping = "pathname";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "bottom";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2025, Bui Huu Dai
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">

<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/bhdai/blog/blob/main/posts/2024-06-30-your-deep-learning-journey/index.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/bhdai/blog/blob/main/posts/2024-06-30-your-deep-learning-journey/index.ipynb" class="toc-action"><i class="bi empty"></i>View source</a></li><li><a href="https://github.com/bhdai/blog/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>
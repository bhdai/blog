<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Bui Huu Dai">
<meta name="dcterms.date" content="2024-11-10">

<title>Exploring Random Forests: The Journey Through Bagging and Boosting – Bui Huu Dai</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-6JR4N915S6"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-6JR4N915S6', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Exploring Random Forests: The Journey Through Bagging and Boosting – Bui Huu Dai">
<meta property="og:description" content="Dai’s blog.">
<meta property="og:image" content="https://buidai123.github.io/blog/posts/2024-11-12-random-forest/random_forest.jpg">
<meta property="og:site_name" content="Bui Huu Dai">
<meta name="twitter:title" content="Exploring Random Forests: The Journey Through Bagging and Boosting – Bui Huu Dai">
<meta name="twitter:description" content="Dai’s blog.">
<meta name="twitter:image" content="https://buidai123.github.io/blog/posts/2024-11-12-random-forest/random_forest.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Bui Huu Dai</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/buidai123"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/daibui1234"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Exploring Random Forests: The Journey Through Bagging and Boosting</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">kaggle</div>
                <div class="quarto-category">competition</div>
                <div class="quarto-category">random forest</div>
                <div class="quarto-category">bagging</div>
                <div class="quarto-category">boosting</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Bui Huu Dai </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 10, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#decision-tree" id="toc-decision-tree" class="nav-link active" data-scroll-target="#decision-tree">Decision Tree</a>
  <ul class="collapse">
  <li><a href="#data-processing" id="toc-data-processing" class="nav-link" data-scroll-target="#data-processing">Data Processing</a></li>
  <li><a href="#binary-split" id="toc-binary-split" class="nav-link" data-scroll-target="#binary-split">Binary Split</a></li>
  <li><a href="#creating-a-tree" id="toc-creating-a-tree" class="nav-link" data-scroll-target="#creating-a-tree">Creating a Tree</a></li>
  </ul></li>
  <li><a href="#random-forest" id="toc-random-forest" class="nav-link" data-scroll-target="#random-forest">Random Forest</a></li>
  <li><a href="#what-else-can-we-do-with-random-forest" id="toc-what-else-can-we-do-with-random-forest" class="nav-link" data-scroll-target="#what-else-can-we-do-with-random-forest">What else can we do with Random Forest</a>
  <ul class="collapse">
  <li><a href="#preparing-stuff" id="toc-preparing-stuff" class="nav-link" data-scroll-target="#preparing-stuff">Preparing Stuff</a></li>
  <li><a href="#decision-tree-ensembles" id="toc-decision-tree-ensembles" class="nav-link" data-scroll-target="#decision-tree-ensembles">Decision Tree Ensembles</a></li>
  <li><a href="#creating-a-random-forest" id="toc-creating-a-random-forest" class="nav-link" data-scroll-target="#creating-a-random-forest">Creating a Random Forest</a></li>
  <li><a href="#out-of-bag-error" id="toc-out-of-bag-error" class="nav-link" data-scroll-target="#out-of-bag-error">Out of Bag Error</a></li>
  <li><a href="#model-interpretation" id="toc-model-interpretation" class="nav-link" data-scroll-target="#model-interpretation">Model Interpretation</a></li>
  </ul></li>
  <li><a href="#extrapolation-and-neuron-networks" id="toc-extrapolation-and-neuron-networks" class="nav-link" data-scroll-target="#extrapolation-and-neuron-networks">Extrapolation and Neuron Networks</a>
  <ul class="collapse">
  <li><a href="#the-extrapolation-problem" id="toc-the-extrapolation-problem" class="nav-link" data-scroll-target="#the-extrapolation-problem">The Extrapolation Problem</a></li>
  <li><a href="#finding-out-of-domain-data" id="toc-finding-out-of-domain-data" class="nav-link" data-scroll-target="#finding-out-of-domain-data">Finding Out-of-Domain Data</a></li>
  <li><a href="#using-neural-networks" id="toc-using-neural-networks" class="nav-link" data-scroll-target="#using-neural-networks">Using Neural Networks</a></li>
  </ul></li>
  <li><a href="#ensembling" id="toc-ensembling" class="nav-link" data-scroll-target="#ensembling">Ensembling</a></li>
  <li><a href="#boosting" id="toc-boosting" class="nav-link" data-scroll-target="#boosting">Boosting</a></li>
  <li><a href="#key-takeaway" id="toc-key-takeaway" class="nav-link" data-scroll-target="#key-takeaway">Key takeaway</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>What’s up! It’s been a long time since the last post, i’m quite lazy recently, but from know i will try to write more blog post though. I’ve revisited the Titanic dataset, this time through the lens of ensemble learning techniques. Previously I wrote about this dataset in this <a href="https://buidai123.github.io/blog/posts/titanic_competition/">blog</a>, but now, let’s dive into why random forests and gradient boosting machine are particularly suitable for tabular data.</p>
<p>You might ask, “Why not just use logistic regression?” While it seems simple, logistic regression can be surprisingly difficult to get right especially with transformation, interactions, and outlier handling. Random forests, on the other hand, offers resilience and robustness that are hard to match, which I’ll explain today.</p>
<p>To start, building a random forest is insightful help demystify the intricacies of machine learning algorithm. I’ll also touch on bagging and boosting, giving a clear view of their strengths</p>
<p>On a practical note, a helpful tip I’ve stumbled upon is using fastai’s import to efficiently bringing in essential libraries like Numpy an pandas. Here’s the snippet to simplify your setup:</p>
<div id="cell-2" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.imports <span class="im">import</span> <span class="op">*</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>np.set_printoptions(linewidth<span class="op">=</span><span class="dv">130</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>These tools and techniques have enhanced my learning journey, and I’m excited to share these insights with you. Alright without any further ado let’s get right into it.</p>
<section id="decision-tree" class="level2">
<h2 class="anchored" data-anchor-id="decision-tree">Decision Tree</h2>
<section id="data-processing" class="level3">
<h3 class="anchored" data-anchor-id="data-processing">Data Processing</h3>
<p>First off, ensure that you have the Titanic dataset downloaded, Here’s the quick setup:</p>
<div id="cell-7" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile, kaggle</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> Path(<span class="st">'titanic'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>kaggle.api.competition_download_cli(<span class="bu">str</span>(path))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>zipfile.ZipFile(<span class="ss">f'</span><span class="sc">{</span>path<span class="sc">}</span><span class="ss">.zip'</span>).extractall(path)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'train.csv'</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>tst_df <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'test.csv'</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>modes <span class="op">=</span> df.mode().iloc[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading titanic.zip to /home/monarch/workplace/random_forest</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 34.1k/34.1k [00:00&lt;00:00, 365kB/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code></code></pre>
</div>
</div>
<p>I’ve previously detailed the intricacies of processing the Titanic dataset in a separate blog post which you might find useful. Fow now, let’s breeze through some basic data processing steps without going into too much detail:</p>
<div id="cell-9" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> proc_data(df):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'Fare'</span>] <span class="op">=</span> df.Fare.fillna(<span class="dv">0</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    df.fillna(modes, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'LogFare'</span>] <span class="op">=</span> np.log1p(df[<span class="st">'Fare'</span>])</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'Embarked'</span>] <span class="op">=</span> pd.Categorical(df.Embarked)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'Sex'</span>] <span class="op">=</span> pd.Categorical(df.Sex)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>proc_data(df)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>proc_data(tst_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Our next task involves organizing the data by identifying continuous and categorical variables, along with dependent variable we’re predicting</p>
<div id="cell-11" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>cats<span class="op">=</span>[<span class="st">"Sex"</span>,<span class="st">"Embarked"</span>]</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>conts<span class="op">=</span>[<span class="st">'Age'</span>, <span class="st">'SibSp'</span>, <span class="st">'Parch'</span>, <span class="st">'LogFare'</span>,<span class="st">"Pclass"</span>]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>dep<span class="op">=</span><span class="st">"Survived"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, a brief look at how <code>Pandas</code> handles categorical variables. Let’s consider the <code>Sex</code> column:</p>
<div id="cell-13" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>df.Sex.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>0      male
1    female
2    female
3    female
4      male
Name: Sex, dtype: category
Categories (2, object): ['female', 'male']</code></pre>
</div>
</div>
<p>It’s fascinating, although it appears unchanged(still just <code>Male</code> and <code>Female</code>), it’s now a category with a predefine list. Behind the magic, Pandas cleverly assigns numerical codes for these categories for efficient processing:</p>
<div id="cell-15" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>df.Sex.cat.codes.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>0    1
1    0
2    0
3    0
4    1
dtype: int8</code></pre>
</div>
</div>
<p>It’s actually turned them into numbers. This transformation sets the stage for our decision tree modeling</p>
</section>
<section id="binary-split" class="level3">
<h3 class="anchored" data-anchor-id="binary-split">Binary Split</h3>
<p>A random forest is essentially an ensemble of decision trees, and each tree is constructed from a series of binary split. But what exactly is a binary split?</p>
<p>Imagine taking all the passengers on the Titanic and dividing them into males and females to examine their survival rates.</p>
<div id="cell-19" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>fig,axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">11</span>,<span class="dv">5</span>))</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df, y<span class="op">=</span>dep, x<span class="op">=</span><span class="st">"Sex"</span>, ax<span class="op">=</span>axs[<span class="dv">0</span>]).<span class="bu">set</span>(title<span class="op">=</span><span class="st">"Survival rate"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>sns.countplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">"Sex"</span>, ax<span class="op">=</span>axs[<span class="dv">1</span>]).<span class="bu">set</span>(title<span class="op">=</span><span class="st">"Histogram"</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>we see a stark difference: about a 20% survival rate for males and 75% for females, there are roughly twice as many males as females. If you base a model solely on sex, predicting survival becomes surprisingly effective: men likely didn’t survive, while who man likely did this division by sex exemplifies a binary split - it simple divide the data into two distinct groups.</p>
<p>To test the efficacy of this basic model, we first split our data into training and test dataset and encode our categorical variables.</p>
<div id="cell-21" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> random</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">42</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>trn_df,val_df <span class="op">=</span> train_test_split(df, test_size<span class="op">=</span><span class="fl">0.25</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>trn_df[cats] <span class="op">=</span> trn_df[cats].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.cat.codes)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>val_df[cats] <span class="op">=</span> val_df[cats].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.cat.codes)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, let’s create function to to extract independent variables (<code>xs</code>) and the dependent variable (<code>y</code>).</p>
<div id="cell-23" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> xs_y(df):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    xs <span class="op">=</span> df[cats<span class="op">+</span>conts].copy()</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> xs,df[dep] <span class="cf">if</span> dep <span class="kw">in</span> df <span class="cf">else</span> <span class="va">None</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>trn_xs,trn_y <span class="op">=</span> xs_y(trn_df)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>val_xs,val_y <span class="op">=</span> xs_y(val_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>From here we make predictions:</p>
<div id="cell-25" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> val_xs.Sex<span class="op">==</span><span class="dv">0</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>mean_absolute_error(val_y, preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>0.21524663677130046</code></pre>
</div>
</div>
<p>A 21.5% error rate isn’t too shabby for such a simple model. Can we do better? Let’s try another variable such as <code>Fare</code> which is continuous.</p>
<div id="cell-27" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>df_fare <span class="op">=</span> trn_df[trn_df.LogFare<span class="op">&gt;</span><span class="dv">0</span>]</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>fig,axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">11</span>,<span class="dv">5</span>))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>sns.boxenplot(data<span class="op">=</span>df_fare, x<span class="op">=</span>dep, y<span class="op">=</span><span class="st">"LogFare"</span>, ax<span class="op">=</span>axs[<span class="dv">0</span>])</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>sns.kdeplot(data<span class="op">=</span>df_fare, x<span class="op">=</span><span class="st">"LogFare"</span>, ax<span class="op">=</span>axs[<span class="dv">1</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The boxenplot shows that those who survived generally paid higher fares.</p>
<p>So here’s another model <code>LogFare</code> greater than 2.7:</p>
<div id="cell-29" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> val_xs.LogFare<span class="op">&gt;</span><span class="fl">2.7</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>mean_absolute_error(val_y, preds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>0.336322869955157</code></pre>
</div>
</div>
<p>Oh, much worse</p>
<p>To evaluate binary split uniformly, regardless of the datatype, We measure how similar the dependent variable values are within each split. We aim for standard deviations within groups, multiplied by group sizes to account for impact differences.</p>
<div id="cell-31" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _side_score(side, y):</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    tot <span class="op">=</span> side.<span class="bu">sum</span>()</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> tot<span class="op">&lt;=</span><span class="dv">1</span>: <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y[side].std()<span class="op">*</span>tot</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> score(col, y, split):</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    lhs <span class="op">=</span> col<span class="op">&lt;=</span>split</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (_side_score(lhs,y) <span class="op">+</span> _side_score(<span class="op">~</span>lhs,y))<span class="op">/</span><span class="bu">len</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>So for example, if we split by Sex, is greater than or less than 0.5.That’ll create two groups, males and females, and that gives us this score.</p>
<div id="cell-33" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>score(trn_xs[<span class="st">"Sex"</span>], trn_y, <span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>0.4078753098206398</code></pre>
</div>
</div>
<p>And if we do LogFare greater than or less than 2.7, it gives us this score.</p>
<div id="cell-35" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>score(trn_xs[<span class="st">"LogFare"</span>], trn_y, <span class="fl">2.7</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>0.4718087395209973</code></pre>
</div>
</div>
<p>Lower scores indicates better splits, with <code>Sex</code> outperforming <code>LogFare</code>. But how can we find a best split point i mean we have to try ourself right? In every values and see if the score improve or not right, well that was pretty inefficient. It would be nice if we could find some automatic wway to do al that. Well, of course we can. If we want to find the best split point for <code>Age</code>, and try each one in turn, and see what score we get, if we made a binary split on that level of <code>Age</code>. So here’s a list of all the possible binary split threshols of <code>Age</code></p>
<div id="cell-37" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>col <span class="op">=</span> trn_xs[<span class="st">"Age"</span>]</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>unq <span class="op">=</span> col.unique()</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>unq.sort()</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>unq</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>array([ 0.42,  0.67,  0.75,  0.83,  0.92,  1.  ,  2.  ,  3.  ,  4.  ,  5.  ,  6.  ,  7.  ,  8.  ,  9.  , 10.  , 11.  , 12.  ,
       13.  , 14.  , 14.5 , 15.  , 16.  , 17.  , 18.  , 19.  , 20.  , 21.  , 22.  , 23.  , 24.  , 24.5 , 25.  , 26.  , 27.  ,
       28.  , 28.5 , 29.  , 30.  , 31.  , 32.  , 32.5 , 33.  , 34.  , 34.5 , 35.  , 36.  , 36.5 , 37.  , 38.  , 39.  , 40.  ,
       40.5 , 41.  , 42.  , 43.  , 44.  , 45.  , 45.5 , 46.  , 47.  , 48.  , 49.  , 50.  , 51.  , 52.  , 53.  , 54.  , 55.  ,
       55.5 , 56.  , 57.  , 58.  , 59.  , 60.  , 61.  , 62.  , 64.  , 65.  , 70.  , 70.5 , 74.  , 80.  ])</code></pre>
</div>
</div>
<p>Let’s go through all of them. For each of them calculate the score and then <code>Numpy</code> and <code>Pytorch</code> have an <code>argmin()</code> function, which tells you what index into that list is the smallest.</p>
<div id="cell-39" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> np.array([score(col, trn_y, o) <span class="cf">for</span> o <span class="kw">in</span> unq <span class="cf">if</span> <span class="kw">not</span> np.isnan(o)])</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>unq[scores.argmin()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>6.0</code></pre>
</div>
</div>
<p>Here’s the scores.</p>
<div id="cell-41" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>scores</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>array([0.48447755, 0.48351588, 0.48158676, 0.48061929, 0.47964987, 0.480937  , 0.48347294, 0.48171397, 0.47987776, 0.47884826,
       0.47831672, 0.47949847, 0.47957573, 0.48092137, 0.48130659, 0.48200571, 0.48163287, 0.48124801, 0.48151498, 0.48183316,
       0.48105614, 0.48202484, 0.48178211, 0.48337829, 0.48439618, 0.48501782, 0.48545475, 0.48556795, 0.48550856, 0.48554074,
       0.48550094, 0.48504976, 0.48480161, 0.48561331, 0.4852559 , 0.48513473, 0.48529147, 0.48530156, 0.48543741, 0.48569729,
       0.48571309, 0.48571467, 0.4856701 , 0.48563657, 0.48579877, 0.48579767, 0.4858019 , 0.48580095, 0.48580002, 0.48580178,
       0.48580211, 0.48579777, 0.4857996 , 0.48580236, 0.48579236, 0.48580043, 0.48580303, 0.4858034 , 0.4857613 , 0.4855666 ,
       0.48579394, 0.48580506, 0.48580434, 0.48580707, 0.48579364, 0.48580788, 0.48581017, 0.48580597, 0.48581077, 0.48576815,
       0.48580167, 0.48545792, 0.48567909, 0.48542059, 0.48557468, 0.48492654, 0.4852198 , 0.48548666, 0.48590271, 0.48601112,
       0.48447755, 0.48543732])</code></pre>
</div>
</div>
<p>Create a function to calculate this for any column:</p>
<div id="cell-43" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> min_col(df, nm):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    col,y <span class="op">=</span> df[nm],df[dep]</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    unq <span class="op">=</span> col.dropna().unique()</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    scores <span class="op">=</span> np.array([score(col, y, o) <span class="cf">for</span> o <span class="kw">in</span> unq <span class="cf">if</span> <span class="kw">not</span> np.isnan(o)])</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> scores.argmin()</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> unq[idx],scores[idx]</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>min_col(trn_df, <span class="st">"Age"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(6.0, 0.47831671750899085)</code></pre>
</div>
</div>
<p>Revealing that is at 6.0 for <code>Age</code>. So now we can just go through and calculates the score for the best split point for each column.</p>
<div id="cell-45" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>cols <span class="op">=</span> cats<span class="op">+</span>conts</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>{o:min_col(trn_df, o) <span class="cf">for</span> o <span class="kw">in</span> cols}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>{'Sex': (0, 0.4078753098206398),
 'Embarked': (0, 0.478833425731479),
 'Age': (6.0, 0.47831671750899085),
 'SibSp': (4, 0.4783740258817423),
 'Parch': (0, 0.4805296527841601),
 'LogFare': (2.4390808375825834, 0.4620823937736595),
 'Pclass': (2, 0.4604826188580666)}</code></pre>
</div>
</div>
<p>And if we do that, we find that the lowest score is Sex. So that is how ew calculate the best binary split. Swe we now know that the model we created earlier with <code>Sex</code> is the best single binary split model we can find.</p>
<p>And this simple thing we just did which is finding a single binary split, actually is a type of model, it has a name too, it’s called OneR. And OneR model it turned out in a review of machine learning methods in the 90s is one of the best, if not the best. It’s not a bad idea to always start creating a baseline of OneR, a dicision tree with a single binary split.</p>
</section>
<section id="creating-a-tree" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-tree">Creating a Tree</h3>
<p>“OneR” is probablyy not going to cut it for a lot of things, though it’s surprisingly effective, but maybe we could go a step further. And the other step further we could go is by creating a maybe “TwoR”. What if we took each of those groups, males and females in the Titanic dataset, and split each of these into two other groups? So split the males into two groups and split the females into two groups. To do that, we can repeat the exact same piece of code we just did, but let’s remove sex from it:</p>
<div id="cell-49" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>cols.remove(<span class="st">"Sex"</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>ismale <span class="op">=</span> trn_df.Sex<span class="op">==</span><span class="dv">1</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>males,females <span class="op">=</span> trn_df[ismale],trn_df[<span class="op">~</span>ismale]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, run the same piece of code that we just did before, but just for the males:</p>
<div id="cell-51" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>{o:min_col(males, o) <span class="cf">for</span> o <span class="kw">in</span> cols}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>{'Embarked': (0, 0.387558187041091),
 'Age': (6.0, 0.37398283710105873),
 'SibSp': (4, 0.38758642275862637),
 'Parch': (0, 0.3874704821461953),
 'LogFare': (2.803360380906535, 0.38048562317581447),
 'Pclass': (1, 0.3815544200436083)}</code></pre>
</div>
</div>
<p>This provides a “OneR” rule for how to predict which males survived the Titanic, Interestingly, age turns out to be the biggest predictor for males whether they were greater than or less than 6 determined their survival odds</p>
<p>Similarity, for females:</p>
<div id="cell-53" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>{o:min_col(females, o) <span class="cf">for</span> o <span class="kw">in</span> cols}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>{'Embarked': (0, 0.4295252982857326),
 'Age': (50.0, 0.4225927658431646),
 'SibSp': (4, 0.42319212059713585),
 'Parch': (3, 0.4193314500446157),
 'LogFare': (4.256321678298823, 0.413505983329114),
 'Pclass': (2, 0.3335388911567602)}</code></pre>
</div>
</div>
<p>The passenger class <code>Pclass</code>, or whether they were in first class or not, was the biggest predictor of survival.</p>
<p>This process generates a decision tree - a serries of binary splits that gradually categorize our data so that in the leaf nodes, we derive strong predictions about survival</p>
<p>We can continue these steps for each of the four groups manually with a couple of extra lines of code, or we can use a decision tree classifier. this class automates the process we just outlined:</p>
<div id="cell-55" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, export_graphviz</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> DecisionTreeClassifier(max_leaf_nodes<span class="op">=</span><span class="dv">4</span>).fit(trn_xs, trn_y)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And one very nice thing it has is it can draw the tree for us. So here’s a tiny little draw_tree function:</p>
<div id="cell-57" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> graphviz</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> draw_tree(t, df, size<span class="op">=</span><span class="dv">10</span>, ratio<span class="op">=</span><span class="fl">0.6</span>, precision<span class="op">=</span><span class="dv">2</span>, <span class="op">**</span>kwargs):</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    s<span class="op">=</span>export_graphviz(t, out_file<span class="op">=</span><span class="va">None</span>, feature_names<span class="op">=</span>df.columns, filled<span class="op">=</span><span class="va">True</span>, rounded<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>                      special_characters<span class="op">=</span><span class="va">True</span>, rotate<span class="op">=</span><span class="va">False</span>, precision<span class="op">=</span>precision, <span class="op">**</span>kwargs)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> graphviz.Source(re.sub(<span class="st">'Tree {'</span>, <span class="ss">f'Tree </span><span class="ch">{{</span><span class="ss"> size=</span><span class="sc">{</span>size<span class="sc">}</span><span class="ss">; ratio=</span><span class="sc">{</span>ratio<span class="sc">}</span><span class="ss">'</span>, s))</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>draw_tree(m, trn_xs, size<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-26-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>And you can see here it’s going to first of all split on sex. Now, it looks a bit weird to say sex is less than or equal to 0.5, but remember our binary characteristics are coded as zero or one. This is just an easy way to denote males versus females.</p>
<p>For females, the next split is based on their class. For males, age is the dedicating facter. This creates our four leaf nodes. For instance, of the females in the first class, 116 survived, and only 4 didn’t showing that being a wealthy woman on the Titanic was quite advantageous. On the other hand, among adult males, 68 survived while 350 perished, illustrating the peril they faced.</p>
<p>This quick summary showcases why decision trees are favoured in exploratory data analysis; they provide a clear picture of key variables driving the dataset and their predictive power</p>
<p>One additional point is the <code>Gini</code> measure, a way of evaluating how good a split is, which i’ve illustrated in the code below:</p>
<div id="cell-59" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gini(cond):</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    act <span class="op">=</span> df.loc[cond, dep]</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">-</span> act.mean()<span class="op">**</span><span class="dv">2</span> <span class="op">-</span> (<span class="dv">1</span><span class="op">-</span>act).mean()<span class="op">**</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To understand this mathematically: if <span class="math inline">\(p\)</span> is a probability of an instance being classified as a positive class, and <span class="math inline">\((1 - p)\)</span> for the negative class, <span class="math inline">\(p^2\)</span> denotes the chance of both randomly selected instances being possitive and <span class="math inline">\((1-p)^2\)</span> being negative. The term <span class="math inline">\((1-p^2 - (1-p)^2)\)</span> gives us the probability of misclassification, subtracting the chances of correctly classifying instances.</p>
<p>Here’s an example of <code>Gini</code> calculation for gender:</p>
<div id="cell-61" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>gini(df.Sex<span class="op">==</span><span class="st">'female'</span>), gini(df.Sex<span class="op">==</span><span class="st">'male'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>(0.3828350034484158, 0.3064437162277842)</code></pre>
</div>
</div>
<p>Here, <code>act.mean()**2</code> is the probability that two randomly selected individual both survived, and <code>(1 - act.mean())**2</code> that both did not. Lower <code>Gini</code> impurity suggests a strong skew in survival outcomes, which can be insightful for decision making or predicting survival likelihood based on gender.</p>
<p>Decision trees thus provide not only visual insights but quantitative ways to discern what’s happening within your dataset.</p>
<div id="cell-63" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>mean_absolute_error(val_y, m.predict(val_xs))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>0.2242152466367713</code></pre>
</div>
</div>
<p>So that was for the “OneR” version. For the decision tree with four leaf nodes, the mean absolute error was 0.224, which is actually a bit worse. This outcome suggest that due to the small size of the dataset, the “OneR” method was impressively effective, and enhancements weren’t substantial enough to be discerned among the randomness of such a small validation set.</p>
<p>To take it further, let’s implement a decision tree with a minimum of 50 samples per leaf node:</p>
<div id="cell-65" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> DecisionTreeClassifier(min_samples_leaf<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>m.fit(trn_xs, trn_y)</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>draw_tree(m, trn_xs, size<span class="op">=</span><span class="dv">12</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-30-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This indicates that each leaf will contain at least 50 samples, in this context passengers on the Titanic. For example, suppose you’ve identified that 67 people were female, first-class, and under 28. That’s the point where the tree ceases splitting further</p>
<p>Let’s evaluate this decision tree:</p>
<div id="cell-67" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>mean_absolute_error(val_y, m.predict(val_xs))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>0.18385650224215247</code></pre>
</div>
</div>
<p>With an absolute error of 0.183, this approach shows a bit of improvement.</p>
<p>An interesting aspect of decision trees is the minimal preprocessing required you may have noticed this advantage. There was no need for dummy variables for category features, and although you can create them, it isn’t necessary. Decision trees can manage without these adjustments. We only took the logarithm of the fare to enhance the visual appearance of our graph but the split would operate identically on the original scale, focusing only on data ordering</p>
<p>Moreover, decision trees are indifferent to outliers, long-tailed distributions, and categorical variables: they handle all these situations effectively.</p>
<p>The take away here is that for tabular data, starting with a decision tree-based approach is prudent. It helps create baselines because they are remarkably resilient and offer a robust performance without intricate tunning</p>
</section>
</section>
<section id="random-forest" class="level2">
<h2 class="anchored" data-anchor-id="random-forest">Random Forest</h2>
<p>Now, what if we wanted to make this more accurate? Could we grow the tree further? We could, but with only 50 samples in these leaves, further splitting would result in the leaf nodes having so little data that their predictions wouldn’t be very meaningful. Naturally, there are limitation to how accurate a decision tree can be. so, what we can do? Enter a fascinating statergy called <a href="https://www.stat.berkeley.edu/~breiman/bagging.pdf">bagging</a>.</p>
<p>Here’s the procedure of bagging:</p>
<ol type="1">
<li>Randomly choose a subset of data rows (a “bootstrap replicate” of the learning set).</li>
<li>Train a model using this subset.</li>
<li>Save that model, then go back to step 1 and repeat several times.</li>
<li>This will give you multiple trained models. predict with all models, and then arverage their predictions to make the final prediction.</li>
</ol>
<p>The core insight of bagging is that although models trained on data subsets will make more errors than a model trained on the full dataset, these errors aren’t correlated across models. Different models will make different errors, and when averaged, those errors offset each other. Thus, average the predictions of all the model sharpens the final prediction with more models providing finer estimations.</p>
<p>In essence, a random forest averages the predictions of numerous decision trees, which are generated randomly varying parameters such as training dataset or tree parameters. Bagging is a particular approach to “ensembling” or combining results from multiple models.</p>
<p>Let’s create one in a few lines. Here’s a function to generate a decision tree:</p>
<div id="cell-71" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_tree(prop<span class="op">=</span><span class="fl">0.75</span>):</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(trn_y)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    idxs <span class="op">=</span> random.choice(n, <span class="bu">int</span>(n<span class="op">*</span>prop))</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> DecisionTreeClassifier(min_samples_leaf<span class="op">=</span><span class="dv">5</span>).fit(trn_xs.iloc[idxs], trn_y.iloc[idxs])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, <code>prop</code> denotes the data proportion used, say 75% each time with <code>n</code> as the sample size. Random samples <code>idxs</code> are selected based on the specified proportion, and a decision tree is built from this subset.</p>
<p>Let’s get 100 trees and compile them into a list:</p>
<div id="cell-73" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>trees <span class="op">=</span> [get_tree() <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">100</span>)]</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>all_probs <span class="op">=</span> [t.predict(val_xs) <span class="cf">for</span> t <span class="kw">in</span> trees]</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>avg_probs <span class="op">=</span> np.stack(all_probs).mean(<span class="dv">0</span>)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>mean_absolute_error(val_y, avg_probs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>0.2272645739910314</code></pre>
</div>
</div>
<p>By collecting predictions from these trees, stacking them, and averaging their predictions, we have our random forest.</p>
<p>Random forests are remarkably simple yet powerful. A key feature is that they also randomly select subset of colums to build decision trees, changing the column subset with each node split. The idea is to maintain randomness, yet retain usefulness. For more efficient implementation, we use <code>RandomForestClassifier</code>:</p>
<div id="cell-75" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>rf <span class="op">=</span> RandomForestClassifier(<span class="dv">100</span>, min_samples_leaf<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>rf.fit(trn_xs, trn_y)<span class="op">;</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>mean_absolute_error(val_y, rf.predict(val_xs))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>0.18834080717488788</code></pre>
</div>
</div>
<p>Here, we specify the number of trees and samples per leaf, then fit the classifier. While our mean absolute error might not surpass a single decision tree due to dataset constraints, it remains robust</p>
<p>One can inspect the built decision trees to identify split columns. Monitoring column improvements in <code>Gini</code> across decision trees yields a <strong>feature importance plot</strong>:</p>
<div id="cell-77" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(<span class="bu">dict</span>(cols<span class="op">=</span>trn_xs.columns, imp<span class="op">=</span>m.feature_importances_)).plot(<span class="st">'cols'</span>, <span class="st">'imp'</span>, <span class="st">'barh'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-35-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Feature importance plots demonstrate a feature’s significance by indicating how frequently and effectively it was used for splits. The <code>Sex</code> variable emerges as most significant, follow by <code>Pclass</code>, with other variables less crucial. And this is another reason, by the way, why the random forest isn’t really particularly helpful, because it’s just a easy split to do, basically all the matter is what class you are in and whether you’re male of female.</p>
<p>Random Forests, due to their versatility with data distribution and categorical variable handling, allow immediate and insightful datasets analyses. For large datasets, they quickly reveal key features, facilitating further focused analysis.</p>
</section>
<section id="what-else-can-we-do-with-random-forest" class="level2">
<h2 class="anchored" data-anchor-id="what-else-can-we-do-with-random-forest">What else can we do with Random Forest</h2>
<p>There are other things that you can do with Random Forests and the Titanic dataset is a small one, so it doesn’t highlight the full power of Random Forests. For a bigger and more numerically interesting dataset, let’s consider the auction price of heavy industrial equipment. This dataset is from The <a href="https://www.kaggle.com/c/bluebook-for-bulldozers/overview">Blue Book for Bulldozers</a> Kaggle competition. I highly recommended taking a peek at the overview and the dataset on the competition page before we start.</p>
<section id="preparing-stuff" class="level3">
<h3 class="anchored" data-anchor-id="preparing-stuff">Preparing Stuff</h3>
<section id="downloading-the-dataset" class="level4">
<h4 class="anchored" data-anchor-id="downloading-the-dataset">Downloading the Dataset</h4>
<div id="cell-83" class="cell">
<details class="code-fold">
<summary>Import stuff click to show the code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastbook <span class="im">import</span> <span class="op">*</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas.api.types <span class="im">import</span> is_string_dtype, is_numeric_dtype, is_categorical_dtype</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.tabular.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dtreeviz.trees <span class="im">import</span> <span class="op">*</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Image, display_svg, SVG</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>warnings.simplefilter(<span class="st">'ignore'</span>, <span class="pp">FutureWarning</span>)</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>pd.options.display.max_rows <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a>pd.options.display.max_columns <span class="op">=</span> <span class="dv">8</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Pick a path to download the dataset:</p>
<div id="cell-86" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>comp <span class="op">=</span> <span class="st">'bluebook-for-bulldozers'</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> URLs.path(comp)</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>path</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>Path('/home/monarch/.fastai/archive/bluebook-for-bulldozers')</code></pre>
</div>
</div>
<p>Use the Kaggle API to download the data to the specified path and extract it:</p>
<div id="cell-88" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> kaggle <span class="im">import</span> api</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> path.exists():</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    path.mkdir(parents<span class="op">=</span>true)</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>    api.competition_download_cli(comp, path<span class="op">=</span>path)</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>    shutil.unpack_archive(<span class="bu">str</span>(path<span class="op">/</span><span class="ss">f'</span><span class="sc">{</span>comp<span class="sc">}</span><span class="ss">.zip'</span>), <span class="bu">str</span>(path))</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>path.ls(file_type<span class="op">=</span><span class="st">'text'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Downloading bluebook-for-bulldozers.zip to /home/monarch/.fastai/archive/bluebook-for-bulldozers</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 48.4M/48.4M [00:07&lt;00:00, 6.52MB/s]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code></code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>(#7) [Path('/home/monarch/.fastai/archive/bluebook-for-bulldozers/Machine_Appendix.csv'),Path('/home/monarch/.fastai/archive/bluebook-for-bulldozers/Test.csv'),Path('/home/monarch/.fastai/archive/bluebook-for-bulldozers/TrainAndValid.csv'),Path('/home/monarch/.fastai/archive/bluebook-for-bulldozers/Valid.csv'),Path('/home/monarch/.fastai/archive/bluebook-for-bulldozers/ValidSolution.csv'),Path('/home/monarch/.fastai/archive/bluebook-for-bulldozers/median_benchmark.csv'),Path('/home/monarch/.fastai/archive/bluebook-for-bulldozers/random_forest_benchmark_test.csv')]</code></pre>
</div>
</div>
<p>I’ll now walk you through the dataset. If you examine the <a href="https://www.kaggle.com/c/bluebook-for-bulldozers/data">Data tab</a> on the competition page, here are the key fields found in train.csv:</p>
<ul>
<li><code>SalesID</code>: The unique identifier of the sale.</li>
<li><code>MachineID</code>: the unique identifier of the machine. A machine can be sold multiple times.</li>
<li><code>saleprice</code>: The auction sale price of the machine (only provided in train.csv)</li>
<li><code>saledate</code>: The date the sale occurred.</li>
</ul>
<p>We begin by reading the training set into Pandas <code>DataFrame</code>. It’s generally advisable to specify <code>low_memory=False</code> unless Pandas runs out of memory and throws an error. By default, <code>low_memory</code> is <code>True</code>, instructing Pandas to process data in chucks, which may lead to inconsistent column data types and subsequent data processing or modeling errors.</p>
<div id="cell-90" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'TrainAndValid.csv'</span>, low_memory<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>df.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>Index(['SalesID', 'SalePrice', 'MachineID', 'ModelID', 'datasource',
       'auctioneerID', 'YearMade', 'MachineHoursCurrentMeter', 'UsageBand',
       'saledate', 'fiModelDesc', 'fiBaseModel', 'fiSecondaryDesc',
       'fiModelSeries', 'fiModelDescriptor', 'ProductSize',
       'fiProductClassDesc', 'state', 'ProductGroup', 'ProductGroupDesc',
       'Drive_System', 'Enclosure', 'Forks', 'Pad_Type', 'Ride_Control',
       'Stick', 'Transmission', 'Turbocharged', 'Blade_Extension',
       'Blade_Width', 'Enclosure_Type', 'Engine_Horsepower', 'Hydraulics',
       'Pushblock', 'Ripper', 'Scarifier', 'Tip_Control', 'Tire_Size',
       'Coupler', 'Coupler_System', 'Grouser_Tracks', 'Hydraulics_Flow',
       'Track_Type', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb',
       'Pattern_Changer', 'Grouser_Type', 'Backhoe_Mounting', 'Blade_Type',
       'Travel_Controls', 'Differential_Type', 'Steering_Controls'],
      dtype='object')</code></pre>
</div>
</div>
<p>That’s many columns to scour! Start by exploring the dataset to familiarize yourself with the data content in each colum. Soon we’ll focus on the most compelling bits.</p>
<p>With ordinal columns, it’s benefical to specify meaningful order. These columns contain strings with an inherent sequence. For example, check out the <code>ProducSize</code> levels:</p>
<div id="cell-92" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'ProductSize'</span>].unique()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>array([nan, 'Medium', 'Small', 'Large / Medium', 'Mini', 'Large', 'Compact'], dtype=object)</code></pre>
</div>
</div>
<p>Instruct Pandas about the relevant order of these levels:</p>
<div id="cell-94" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>sizes <span class="op">=</span> <span class="st">'Large'</span>,<span class="st">'Large / Medium'</span>,<span class="st">'Medium'</span>,<span class="st">'Small'</span>,<span class="st">'Mini'</span>,<span class="st">'Compact'</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'ProductSize'</span>] <span class="op">=</span> df[<span class="st">'ProductSize'</span>].astype(<span class="st">'category'</span>)</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'ProductSize'</span>].cat.set_categories(sizes, ordered<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>0            NaN
1         Medium
2            NaN
3          Small
4            NaN
           ...  
412693      Mini
412694      Mini
412695      Mini
412696      Mini
412697      Mini
Name: ProductSize, Length: 412698, dtype: category
Categories (6, object): ['Large' &lt; 'Large / Medium' &lt; 'Medium' &lt; 'Small' &lt; 'Mini' &lt; 'Compact']</code></pre>
</div>
</div>
<p>In this dataset, Kaggle suggests using Root Mean Square Log Error (RMSLE) as the metric for comparing actual versus predicted auction prices.</p>
<div id="cell-96" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>dep_var <span class="op">=</span> <span class="st">'SalePrice'</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>df[dep_var] <span class="op">=</span> np.log(df[dep_var])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This transformation ensures that the target variables is in format suitable for modeling.</p>
</section>
<section id="data-preparation" class="level4">
<h4 class="anchored" data-anchor-id="data-preparation">Data Preparation</h4>
<p>The first piece of data preparation we need to to do is enrich our representation of dates. The fundamental basis of the decision tree that we just discussed is bisection (dividing a group into two). We look at the ordinal variables and divide the dataset based on whether the variables’s value is greater (ow lower) than a theshold, and we look at the categorical variables and divide the dataset based on whether the variable’s level is a particular level. This algorithm divides the dataset based on both original and categorical data</p>
<p>But how does this apply to a common data type, the date? You might want to tree at date as an ordinal value because it is meaningful to say that one date is greate than other. However, dates are a bit different from most ordinal values in that some dates are qualitatively different from others, which is often relevant to the systems we are modeling.</p>
<p>To help our algorithm handle dates intelligently, we’d like our model to know ore than whether a date is more recent or less recent than other. We might want our model to make decisions based on that date’s day of the week, on whether a day is holiday, on what month it is in, and so forth. To accomplish this, we replace every date column with a set of date metadata columns, sush as holiday, day of the week, and month. these columns provide categorical data that we suspect will be useful.</p>
<p>Fastai comes with a function to do this for us that mean we only need to pass in a column name that contains dates:</p>
<div id="cell-100" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> add_datepart(df, <span class="st">'saledate'</span>)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a><span class="co"># do the same for the test set</span></span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>df_test <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'Test.csv'</span>, low_memory<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a>df_test <span class="op">=</span> add_datepart(df_test, <span class="st">'saledate'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can see that there are now many new columns in our <code>DataFrame</code>:</p>
<div id="cell-102" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co">' '</span>.join(o <span class="cf">for</span> o <span class="kw">in</span> df.columns <span class="cf">if</span> o.startswith(<span class="st">'sale'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>'saleYear saleMonth saleWeek saleDay saleDayofweek saleDayofyear saleIs_month_end saleIs_month_start saleIs_quarter_end saleIs_quarter_start saleIs_year_end saleIs_year_start saleElapsed'</code></pre>
</div>
</div>
<p>This a solid first steop, but we need further data cleaning. For this, we will use fastai objects called <code>TabularPandas</code> and <code>TabularProc</code>.</p>
<p>Another aspect of preparatory processing is ensuring we can handle strings and missing data. We will use fastai’s class <code>TabularPandas</code>, which wraps a Pandas <code>DataFrame</code> and offers some conveniences. when we say it “wraps” a <code>DataFrame</code>, it means taking a Pandas <code>DataFrame</code> as input and adding additional specifically useful for machine-learning tasks with tabular data. To populate a <code>TabularPandas</code>, we will utilize two <code>TabularProcs</code>: <code>Categorify</code> and <code>FillMissing</code>.</p>
<p><code>TabularProcs</code> are unique data transformation process used in fastai designed to prepare you data to ML models. We introduce two speicfic <code>TabularProcs</code> here:</p>
<ul>
<li><code>Categorify</code>: convert categorical columns text or non numeric data into numeric categories. For instance, a column <code>Color</code> with values like “Red”, “Blue”, “Green” could be encoded as 1, 2, 3.</li>
<li><code>FillMissing</code>: Manages missing data in your dataset. it replaces missing values with the column’s median value and creates a new boolean column to flag rows that orginally had missing values.</li>
</ul>
<p>How <code>TabularProc</code> differs from regular transforms:</p>
<ul>
<li>Returns the exact same object that’s passed to it, after modifying the object in place, which optimizes memory efficiency especially with large datasets.</li>
<li>Executes the transformation immediately when the data is first passed in rather than delaying until the data is accessed.</li>
</ul>
<p>In practical terms, when using <code>TabularPandas</code> with <code>TabularProcs</code>:</p>
<ol type="1">
<li>Start with your raw data in a Pandas <code>DataFrame</code>.</li>
<li>Wrap this <code>DataFrame</code> with <code>TabularPandas</code>.</li>
<li>Apply <code>TabularProcs</code> (<code>Categorify</code> and <code>FillMissing</code>)</li>
<li>These procs instantly process all your data, converting categories to numbers and filling in missing values.</li>
<li>The outcome is a dataset ready for machine learning models, with all categorical data converted and missing values addressed.</li>
</ol>
<p>This methodology streamlines the data preparation process, ensure consistent data processing ready for model training or inference.</p>
<div id="cell-104" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>procs <span class="op">=</span> [Categorify, FillMissing]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>TabularPandas</code> will also manage the dataset split into training and validation sets for us.</p>
</section>
<section id="handling-a-time-series" class="level4">
<h4 class="anchored" data-anchor-id="handling-a-time-series">Handling a Time Series</h4>
<p>When dealing with time series data, randomly selecting a subset of data points for training and validation is not sufficient, as sequence of data is vital. The test set represents a future six-month period starting from May 2012, thus not overlapping with the training set. This setup is intentional because the competition sponsor aims to evaluate the model’s predictive capability selected from a later time than your training dataset.</p>
<p>The provided Kaggle training data concludes in April 2012. Therefore, we’ll construct to focused training dataset comprising data from before November 2011 and establish a validation set with data from after November 2011.</p>
<p>This is achieved using <code>np.where</code>, which helps in obtaining indices for specific conditions:</p>
<div id="cell-108" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>cond <span class="op">=</span> (df.saleYear<span class="op">&lt;</span><span class="dv">2011</span>) <span class="op">|</span> (df.saleMonth<span class="op">&lt;</span><span class="dv">10</span>)</span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a>train_idx <span class="op">=</span> np.where( cond)[<span class="dv">0</span>]</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>valid_idx <span class="op">=</span> np.where(<span class="op">~</span>cond)[<span class="dv">0</span>]</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>splits <span class="op">=</span> (<span class="bu">list</span>(train_idx),<span class="bu">list</span>(valid_idx))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>TabularPandas requires knowledge of which columns are continuos and which are categorical. We can simplify this with the <code>cont_cat_split</code> helper function:</p>
<div id="cell-110" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>cont,cat <span class="op">=</span> cont_cat_split(df, <span class="dv">1</span>, dep_var<span class="op">=</span>dep_var)</span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>to <span class="op">=</span> TabularPandas(df, procs, cat, cont, y_names<span class="op">=</span>dep_var, splits<span class="op">=</span>splits)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This setup turns <code>TabularPandas</code>into something akin to a fastai <code>Dataset</code> object, with accessible tain and valid attributes:</p>
<div id="cell-112" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(to.train),<span class="bu">len</span>(to.valid)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>(404710, 7988)</code></pre>
</div>
</div>
<p>It’s possible to view the dataset’s categorical varibales still represented as strings:</p>
<div id="cell-114" class="cell">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>to.show(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">UsageBand</th>
<th data-quarto-table-cell-role="th">fiModelDesc</th>
<th data-quarto-table-cell-role="th">fiBaseModel</th>
<th data-quarto-table-cell-role="th">fiSecondaryDesc</th>
<th data-quarto-table-cell-role="th">fiModelSeries</th>
<th data-quarto-table-cell-role="th">fiModelDescriptor</th>
<th data-quarto-table-cell-role="th">ProductSize</th>
<th data-quarto-table-cell-role="th">fiProductClassDesc</th>
<th data-quarto-table-cell-role="th">state</th>
<th data-quarto-table-cell-role="th">ProductGroup</th>
<th data-quarto-table-cell-role="th">ProductGroupDesc</th>
<th data-quarto-table-cell-role="th">Drive_System</th>
<th data-quarto-table-cell-role="th">Enclosure</th>
<th data-quarto-table-cell-role="th">Forks</th>
<th data-quarto-table-cell-role="th">Pad_Type</th>
<th data-quarto-table-cell-role="th">Ride_Control</th>
<th data-quarto-table-cell-role="th">Stick</th>
<th data-quarto-table-cell-role="th">Transmission</th>
<th data-quarto-table-cell-role="th">Turbocharged</th>
<th data-quarto-table-cell-role="th">Blade_Extension</th>
<th data-quarto-table-cell-role="th">Blade_Width</th>
<th data-quarto-table-cell-role="th">Enclosure_Type</th>
<th data-quarto-table-cell-role="th">Engine_Horsepower</th>
<th data-quarto-table-cell-role="th">Hydraulics</th>
<th data-quarto-table-cell-role="th">Pushblock</th>
<th data-quarto-table-cell-role="th">Ripper</th>
<th data-quarto-table-cell-role="th">Scarifier</th>
<th data-quarto-table-cell-role="th">Tip_Control</th>
<th data-quarto-table-cell-role="th">Tire_Size</th>
<th data-quarto-table-cell-role="th">Coupler</th>
<th data-quarto-table-cell-role="th">Coupler_System</th>
<th data-quarto-table-cell-role="th">Grouser_Tracks</th>
<th data-quarto-table-cell-role="th">Hydraulics_Flow</th>
<th data-quarto-table-cell-role="th">Track_Type</th>
<th data-quarto-table-cell-role="th">Undercarriage_Pad_Width</th>
<th data-quarto-table-cell-role="th">Stick_Length</th>
<th data-quarto-table-cell-role="th">Thumb</th>
<th data-quarto-table-cell-role="th">Pattern_Changer</th>
<th data-quarto-table-cell-role="th">Grouser_Type</th>
<th data-quarto-table-cell-role="th">Backhoe_Mounting</th>
<th data-quarto-table-cell-role="th">Blade_Type</th>
<th data-quarto-table-cell-role="th">Travel_Controls</th>
<th data-quarto-table-cell-role="th">Differential_Type</th>
<th data-quarto-table-cell-role="th">Steering_Controls</th>
<th data-quarto-table-cell-role="th">saleIs_month_end</th>
<th data-quarto-table-cell-role="th">saleIs_month_start</th>
<th data-quarto-table-cell-role="th">saleIs_quarter_end</th>
<th data-quarto-table-cell-role="th">saleIs_quarter_start</th>
<th data-quarto-table-cell-role="th">saleIs_year_end</th>
<th data-quarto-table-cell-role="th">saleIs_year_start</th>
<th data-quarto-table-cell-role="th">auctioneerID_na</th>
<th data-quarto-table-cell-role="th">MachineHoursCurrentMeter_na</th>
<th data-quarto-table-cell-role="th">SalesID</th>
<th data-quarto-table-cell-role="th">MachineID</th>
<th data-quarto-table-cell-role="th">ModelID</th>
<th data-quarto-table-cell-role="th">datasource</th>
<th data-quarto-table-cell-role="th">auctioneerID</th>
<th data-quarto-table-cell-role="th">YearMade</th>
<th data-quarto-table-cell-role="th">MachineHoursCurrentMeter</th>
<th data-quarto-table-cell-role="th">saleYear</th>
<th data-quarto-table-cell-role="th">saleMonth</th>
<th data-quarto-table-cell-role="th">saleWeek</th>
<th data-quarto-table-cell-role="th">saleDay</th>
<th data-quarto-table-cell-role="th">saleDayofweek</th>
<th data-quarto-table-cell-role="th">saleDayofyear</th>
<th data-quarto-table-cell-role="th">saleElapsed</th>
<th data-quarto-table-cell-role="th">SalePrice</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>Low</td>
<td>521D</td>
<td>521</td>
<td>D</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>Wheel Loader - 110.0 to 120.0 Horsepower</td>
<td>Alabama</td>
<td>WL</td>
<td>Wheel Loader</td>
<td>#na#</td>
<td>EROPS w AC</td>
<td>None or Unspecified</td>
<td>#na#</td>
<td>None or Unspecified</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>2 Valve</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>None or Unspecified</td>
<td>None or Unspecified</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>Standard</td>
<td>Conventional</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>1139246</td>
<td>999089</td>
<td>3157</td>
<td>121</td>
<td>3.0</td>
<td>2004</td>
<td>68.0</td>
<td>2006</td>
<td>11</td>
<td>46</td>
<td>16</td>
<td>3</td>
<td>320</td>
<td>1.163635e+09</td>
<td>11.097410</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>Low</td>
<td>950FII</td>
<td>950</td>
<td>F</td>
<td>II</td>
<td>#na#</td>
<td>Medium</td>
<td>Wheel Loader - 150.0 to 175.0 Horsepower</td>
<td>North Carolina</td>
<td>WL</td>
<td>Wheel Loader</td>
<td>#na#</td>
<td>EROPS w AC</td>
<td>None or Unspecified</td>
<td>#na#</td>
<td>None or Unspecified</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>2 Valve</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>23.5</td>
<td>None or Unspecified</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>Standard</td>
<td>Conventional</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>1139248</td>
<td>117657</td>
<td>77</td>
<td>121</td>
<td>3.0</td>
<td>1996</td>
<td>4640.0</td>
<td>2004</td>
<td>3</td>
<td>13</td>
<td>26</td>
<td>4</td>
<td>86</td>
<td>1.080259e+09</td>
<td>10.950807</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>High</td>
<td>226</td>
<td>226</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>Skid Steer Loader - 1351.0 to 1601.0 Lb Operating Capacity</td>
<td>New York</td>
<td>SSL</td>
<td>Skid Steer Loaders</td>
<td>#na#</td>
<td>OROPS</td>
<td>None or Unspecified</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>Auxiliary</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>None or Unspecified</td>
<td>None or Unspecified</td>
<td>None or Unspecified</td>
<td>Standard</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>#na#</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>False</td>
<td>1139249</td>
<td>434808</td>
<td>7009</td>
<td>121</td>
<td>3.0</td>
<td>2001</td>
<td>2838.0</td>
<td>2004</td>
<td>2</td>
<td>9</td>
<td>26</td>
<td>3</td>
<td>57</td>
<td>1.077754e+09</td>
<td>9.210340</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>However, all underlying data has been coverted to numeric form:</p>
<div id="cell-116" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>to.items.head(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">SalesID</th>
<th data-quarto-table-cell-role="th">SalePrice</th>
<th data-quarto-table-cell-role="th">MachineID</th>
<th data-quarto-table-cell-role="th">ModelID</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">saleIs_year_start</th>
<th data-quarto-table-cell-role="th">saleElapsed</th>
<th data-quarto-table-cell-role="th">auctioneerID_na</th>
<th data-quarto-table-cell-role="th">MachineHoursCurrentMeter_na</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1139246</td>
<td>11.097410</td>
<td>999089</td>
<td>3157</td>
<td>...</td>
<td>1</td>
<td>1.163635e+09</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1139248</td>
<td>10.950807</td>
<td>117657</td>
<td>77</td>
<td>...</td>
<td>1</td>
<td>1.080259e+09</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1139249</td>
<td>9.210340</td>
<td>434808</td>
<td>7009</td>
<td>...</td>
<td>1</td>
<td>1.077754e+09</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

<p>3 rows × 67 columns</p>
</div>
</div>
</div>
<p>Categorical columns undergo transformation by substituting each unique category with a number. These numbers are assigned consecutively as they first appear, implying no intrinsic value to these numbers, unless ordered categories (like <code>ProductSize</code>) pre-specify the sequence. You can check the mapping through the classes attribute:</p>
<div id="cell-118" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a>to.classes[<span class="st">'ProductSize'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>['#na#', 'Compact', 'Large', 'Large / Medium', 'Medium', 'Mini', 'Small']</code></pre>
</div>
</div>
<p>A neat feature in fastai is the ability to save processed data, which can be time-consuming. Saving the data alows you to resume further work without repeating the preprocessing steps. Fastai utilizes Python’s pickle system for this purpose:</p>
<div id="cell-120" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>save_pickle(path<span class="op">/</span><span class="st">'to.pkl'</span>,to)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>to retrieve it later you’ll simply do:</p>
<div id="cell-122" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>to <span class="op">=</span> load_pickle(path<span class="op">/</span><span class="st">'to.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With preprocessing complete, we’re set to create a decision tree.</p>
</section>
</section>
<section id="decision-tree-ensembles" class="level3">
<h3 class="anchored" data-anchor-id="decision-tree-ensembles">Decision Tree Ensembles</h3>
<p>Let’s consider how we find the right questions to ask when creating decision trees. Fortunately we don’t have to do this manually computer are designed for this purpose! Here’s a simple overview of training a decision tree:</p>
<ol type="1">
<li>Loop through each column of the dataset in turn.</li>
<li>For each column, loop through each possible level of that column in turn.</li>
<li>Try splitting the data into two groups, based on whether they are greater than or less than that value (or if it is a categorical variable, based on whether they are equal to or not equal to that level of that categorical variable).</li>
<li>Find the average sale price for each of those two groups, and see how close that is to the actual sale price of each of the items of equipment in that group. That is, treat this as a very simple “model” where our predictions are simply the average sale price of the item’s group.</li>
<li>After looping through all of the columns and all the possible levels for each, pick the split point that gave the best predictions using that simple model.</li>
<li>We now have two different groups for our data, based on this selected split. Treat each of these as separate datasets, and find the best split for each by going back to step 1 for each group.</li>
<li>Continue this process recursively, until you have reached some stopping criterion for each group—for instance, stop splitting a group further when it has only 20 items in it.</li>
</ol>
<p>To implement this, start by defining your independent and dependent variables:</p>
<div id="cell-126" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>xs,y <span class="op">=</span> to.train.xs,to.train.y</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>valid_xs,valid_y <span class="op">=</span> to.valid.xs,to.valid.y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-127" class="cell">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>xs.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">UsageBand</th>
<th data-quarto-table-cell-role="th">fiModelDesc</th>
<th data-quarto-table-cell-role="th">fiBaseModel</th>
<th data-quarto-table-cell-role="th">fiSecondaryDesc</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">saleDay</th>
<th data-quarto-table-cell-role="th">saleDayofweek</th>
<th data-quarto-table-cell-role="th">saleDayofyear</th>
<th data-quarto-table-cell-role="th">saleElapsed</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>2</td>
<td>963</td>
<td>298</td>
<td>43</td>
<td>...</td>
<td>16</td>
<td>3</td>
<td>320</td>
<td>1.163635e+09</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>1745</td>
<td>529</td>
<td>57</td>
<td>...</td>
<td>26</td>
<td>4</td>
<td>86</td>
<td>1.080259e+09</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>336</td>
<td>111</td>
<td>0</td>
<td>...</td>
<td>26</td>
<td>3</td>
<td>57</td>
<td>1.077754e+09</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>3716</td>
<td>1381</td>
<td>0</td>
<td>...</td>
<td>19</td>
<td>3</td>
<td>139</td>
<td>1.305763e+09</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>3</td>
<td>4261</td>
<td>1538</td>
<td>0</td>
<td>...</td>
<td>23</td>
<td>3</td>
<td>204</td>
<td>1.248307e+09</td>
</tr>
</tbody>
</table>

<p>5 rows × 66 columns</p>
</div>
</div>
</div>
<p>Once your data is numeric and lacks missing values, you can create a decision tree:</p>
<div id="cell-129" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> DecisionTreeRegressor(max_leaf_nodes<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>m.fit(xs, y)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we’ve instructed sklearn to create four leaf nodes. To visualize what the model has learned, we can display the tree:</p>
<div id="cell-131" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>draw_tree(m, xs, size<span class="op">=</span><span class="dv">10</span>, leaves_parallel<span class="op">=</span><span class="va">True</span>, precision<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-58-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Understanding this visualization helps in graphing decision tree:</p>
<ol type="1">
<li><p>Top node: Represents the entire dataset before any splits. Average sale price (log) is 10.10, with a mean squared error of 0.48.</p></li>
<li><p>First split: Based on coupler_system.</p></li>
</ol>
<ul>
<li>Left branch: coupler_system &lt; 0.5 (360,847 records, avg. 10.21)</li>
<li>Right branch: coupler_system &gt; 0.5 (43,863 records, avg. 9.21)</li>
</ul>
<ol start="3" type="1">
<li>Second split (on left branch): Based on <code>YearMade</code>.</li>
</ol>
<ul>
<li>Left sub-branch: <code>YearMade</code> &lt;= 1991.5 (155,724 records, avg. 9.97)</li>
<li>Right sub-branch: <code>YearMade</code> &gt; 1991.5 (205,123 records, avg. 10.4)</li>
</ul>
<ol start="4" type="1">
<li>Leaf nodes: The bottom row, where no more splits occur.</li>
</ol>
<p>We can display this information using Terence Parr’s dtreeviz library to enhance visualization:</p>
<div id="cell-133" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>samp_idx <span class="op">=</span> np.random.permutation(<span class="bu">len</span>(y))[:<span class="dv">500</span>]</span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a>dtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,</span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>        fontname<span class="op">=</span><span class="st">'DejaVu Sans'</span>, scale<span class="op">=</span><span class="fl">1.6</span>, label_fontsize<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>        orientation<span class="op">=</span><span class="st">'LR'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-59-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This visualization illuminates data distribution, showcasing issues like bulldozers dated to the year 1000, likely placeholders for missing data. For modeling precision, these can be substituted with 1950 to improve visualization clarity without significantly influencing model results:</p>
<div id="cell-135" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>xs.loc[xs[<span class="st">'YearMade'</span>]<span class="op">&lt;</span><span class="dv">1900</span>, <span class="st">'YearMade'</span>] <span class="op">=</span> <span class="dv">1950</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>valid_xs.loc[valid_xs[<span class="st">'YearMade'</span>]<span class="op">&lt;</span><span class="dv">1900</span>, <span class="st">'YearMade'</span>] <span class="op">=</span> <span class="dv">1950</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This update clarifies the tree visualization while maintaining the models integrity. After making this change, re-evaluate the decision tree:</p>
<div id="cell-137" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> DecisionTreeRegressor(max_leaf_nodes<span class="op">=</span><span class="dv">4</span>).fit(xs, y)</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>dtreeviz(m, xs.iloc[samp_idx], y.iloc[samp_idx], xs.columns, dep_var,</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>        fontname<span class="op">=</span><span class="st">'DejaVu Sans'</span>, scale<span class="op">=</span><span class="fl">1.6</span>, label_fontsize<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a>        orientation<span class="op">=</span><span class="st">'LR'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-61-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Now, let’s leverage the decision tree algorithm to generate a more complex model. This time, we’ll refrain from specifying any stopping criteria, such as <code>max_leaf_nodes</code>:</p>
<div id="cell-139" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> DecisionTreeRegressor()</span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>m.fit(xs, y)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To evaluate our model’s performance, we’ll define a function to compute the root mean squared error(RMSE) which was the scoring criterion in this competition:</p>
<div id="cell-141" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> r_mse(pred,y): <span class="cf">return</span> <span class="bu">round</span>(math.sqrt(((pred<span class="op">-</span>y)<span class="op">**</span><span class="dv">2</span>).mean()), <span class="dv">6</span>)</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> m_rmse(m, xs, y): <span class="cf">return</span> r_mse(m.predict(xs), y)</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a>m_rmse(m, xs, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>0.0</code></pre>
</div>
</div>
<p>The output is 0.0. At the first glance, it appears that our model is flawless. But hold on, we need to evalueate the validation set to check for overfitting:</p>
<div id="cell-143" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>m_rmse(m, valid_xs, valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>0.332239</code></pre>
</div>
</div>
<p>The validation set RMSE is 0.332239, indicating potential overfitting. Let’s investigating further</p>
<div id="cell-145" class="cell">
<div class="sourceCode cell-code" id="cb98"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a>m.get_n_leaves(), <span class="bu">len</span>(xs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>(324338, 404710)</code></pre>
</div>
</div>
<p>It turns out our model hsa nearly as many leaves as data point! This occurs because sklearn’s default setting allow continual splitting until there’s just one item per leaf node. We can address this by adjusting the stopping rule to require each leaf node to have at least 25 auction records:</p>
<div id="cell-147" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> DecisionTreeRegressor(min_samples_leaf<span class="op">=</span><span class="dv">25</span>)</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>m.fit(to.train.xs, to.train.y)</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>(0.243049, 0.308857)</code></pre>
</div>
</div>
<p>This results in a more balanced model. Let’s verify the new number of leaves:</p>
<div id="cell-149" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>m.get_n_leaves()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>12432</code></pre>
</div>
</div>
<p>Decision trees are adept at modelling data due to their adaptability to nonlinear relationships and variable interactions. Nonetheless, a compromise exist between generallizability (achieved with smaller trees) and training accuracy (achieved with larger trees)</p>
<p>How do wee balance these strengths? We’ll explore further after covering essential aspect handling categorical variables.</p>
<p>In deep learning, categorical variables are often one-hot encoded and fed into embedding layers. However, decision trees lack embedding layers so how can we leverage untreated categorical variables efficiently? let’s consider a use-case with product codes.</p>
<p>Suppose we have an auction dataset with product codes (categorical variables) and sale prices. “Product X” for instance, consistently sells at a premium. Decision trees split data based on features optimally partition the target variable. A split distinguishing “Product X” from others creates:</p>
<ul>
<li>Group A: containing product X</li>
<li>Group B: containing all other products</li>
</ul>
<p>This chose arises because “Product X” is notably pricier, leading Group A to have a higher average price than Group B. This split provides valuable insights for price prediction, prompting the algorithm to prefer it. The decision tree isolates “Product X” quickly, allowing pricise price predictions while evaluating other products’ prices.</p>
<p>One-hot encoding is another option; it transforms a single categorical column into multiple binary columns, each representing a category level. Pandas offers the <code>get_dummies</code> method which does just that.</p>
<p>However, there’s little evidence that one-hot encoding enhances results. Thus, we tend to avoid it when unnecessary, as it complicates data handling.</p>
</section>
<section id="creating-a-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-random-forest">Creating a Random Forest</h3>
<p>Creating a random forest involves a process similar to crafting a decision tree, but with added flexibility through paramaters that determine the number of trees, data point subset size(rows), and field subset size(columns):</p>
<div id="cell-153" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rf(xs, y, n_estimators<span class="op">=</span><span class="dv">40</span>, max_samples<span class="op">=</span><span class="dv">200_000</span>,</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a>       max_features<span class="op">=</span><span class="fl">0.5</span>, min_samples_leaf<span class="op">=</span><span class="dv">5</span>, <span class="op">**</span>kwargs):</span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> RandomForestRegressor(n_jobs<span class="op">=-</span><span class="dv">1</span>, n_estimators<span class="op">=</span>n_estimators,</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a>        max_samples<span class="op">=</span>max_samples, max_features<span class="op">=</span>max_features,</span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a>        min_samples_leaf<span class="op">=</span>min_samples_leaf, oob_score<span class="op">=</span><span class="va">True</span>).fit(xs, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here’s an explanation of the parameters used in the function:</p>
<ul>
<li><code>n_estimators</code>: specifies the number of tree in the forest.</li>
<li><code>max_samples</code>: indicates how many rows to sample when training each tree.</li>
<li><code>max_features</code>: sets the number of columns to sample at each split (e.g., 0.5 means using half of the columns).</li>
<li><code>min_samples_leaf</code>: determines the minimum number of samples required in the leaf node, controlling the tree depth.</li>
</ul>
<p>Additionally, <code>n_jobs=-1</code> ensures that all available CPUs are utilized for parallel tree building. This function allows quick experimentation with different configurations.</p>
<p>Initiating the random forest model is straightforward:</p>
<div id="cell-155" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> rf(xs, y)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>By using multiple trees rather than a single <code>DecisionTreeRegressor</code>, the validation RMSE significantly improves:</p>
<div id="cell-157" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>m_rmse(m, xs, y), m_rmse(m, valid_xs, valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>(0.171371, 0.233223)</code></pre>
</div>
</div>
<p>A distinctive feature of random forests is the resilience hyperparameter configurations, particularly <code>max_features</code>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>When we say random forests show resilience to hyperparameter configurations, it means that the algorithm performs well across a range of different hyperparameter settings. It doesn’t require very precise tuning to achieve good results, making it a flexible option in many applications.</p>
</div>
</div>
<p>The N_estimators parameter can be set to as high as value as feasible, the more trees, the greater the accuracy potential</p>
<p>For visualizing effects of varying max_features with increasing tree counts, refer to sklearn’s documentation which provides insightful plots.</p>
<p><img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_ensemble_oob_001.png"></p>
<p>The image demonstrates:</p>
<ul>
<li>Blue line: represents minimal features usage.</li>
<li>Green line: represents maximal feature usage (full feature set). Subsets of features combined with numerous trees usualy yield the lowest error.</li>
</ul>
<p>To explore the impact of <code>n_estimators</code> analyze predictions from each individual tree within the forest (accessible via the <code>estimators_</code> attribute):</p>
<div id="cell-159" class="cell">
<div class="sourceCode cell-code" id="cb108"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> np.stack([t.predict(valid_xs) <span class="cf">for</span> t <span class="kw">in</span> m.estimators_])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-160" class="cell">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>r_mse(preds.mean(<span class="dv">0</span>), valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>0.233223</code></pre>
</div>
</div>
<p>This calculation, <code>preds.mean(0)</code>, parallels the overall random forest prediction. Observe RMSE progression as trees are added:</p>
<div id="cell-162" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>plt.plot([r_mse(preds[:i<span class="op">+</span><span class="dv">1</span>].mean(<span class="dv">0</span>), valid_y) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">40</span>)])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-73-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Despite improved RMSE in training, the validation set’s performance may deteriorate due to potential overfitting or time discrepancies. This challenge is addressable by leveraging the out-of-bag (OOB) error methodology in random forests, offering valuable insights.</p>
<p>In the next section, we’ll delve deeper into creating a random forest and optimizing it’s performance.</p>
</section>
<section id="out-of-bag-error" class="level3">
<h3 class="anchored" data-anchor-id="out-of-bag-error">Out of Bag Error</h3>
<p>In a random forest, each tree is trained on different subset of data. Consequently, there’s a unique opportunity: each tree has an implicit valication set composed of the data rows not selected for its training, know as out-of-bag (OOB) data.</p>
<p>OOB error is particularly useful when dealing with a limited dataset, as it offers a measure of model generalization without needing to withhold data for a separate validation set. These OOB predictions are stored in the <code>oob_prediction_</code> attribute. Remember, these are compared with training labels, as the OOB calculation involves the training set:</p>
<div id="cell-166" class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>r_mse(m.oob_prediction_, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>0.211234</code></pre>
</div>
</div>
<p>The OOB error frequently appears lower than the validation set error, hinting that other factors might contiribute to the validation error, hinting that other factors might contribute to the validation error outside mere generalization discrepancies. We’ll delve into these causes soon.</p>
</section>
<section id="model-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="model-interpretation">Model Interpretation</h3>
<p>Interpreting models trained on tabular data presents valuable insights. Higher understanding can be sought in ares like:</p>
<ul>
<li>How confident are we in our predictions using a particular row of data?</li>
<li>For predicting with a particular row of data, what were the most important factors, and how did they influence that prediction?</li>
<li>Which columns are the strongest predictors, which can we ignore?</li>
<li>Which columns are effectively redundant with each other, for purposes of prediction?</li>
<li>How do predictions vary, as we vary these columns?</li>
</ul>
<p>Random forests are adept at addressing these questions. Let’s start with evaluating confidence in predictions!</p>
<p>Model predctions are an average of individual tree predictions, providing an estimated value. But how can we gauge the confiidence of this estimate? One simplistic approach is using the standard deviations of tree predictions - higher deviations imply less confidence, suggseting that caution is needed, especially in scenarios where tree predictions are inconsistent.</p>
<p>In creating the random forest, predictions over the validations set were obtained using Python’s list comprehension:</p>
<div id="cell-170" class="cell">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>preds <span class="op">=</span> np.stack([t.predict(valid_xs) <span class="cf">for</span> t <span class="kw">in</span> m.estimators_])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-171" class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>preds.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>(40, 7988)</code></pre>
</div>
</div>
<p>This results in a prediction for each tree accross all validation set auctions (40 trees, 7,988 auctions). With this data, compute the standard deviation of predictions for each auction:</p>
<div id="cell-173" class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a>preds_std <span class="op">=</span> preds.std(<span class="dv">0</span>)</span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a>preds_std[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>array([0.2000169 , 0.08355874, 0.113672  , 0.2747    , 0.12065141])</code></pre>
</div>
</div>
<p>The standard deviations highlight varying levels of confidence across auctions. A lower deviation signals stronger agreement among trees, leading to higher confidence. Conversely, higher deviations indicate disagreement, pointing towards lower confidence. In practical applications like auction bidding, this information is useful; you might reconsider bidding when predictions show low certainty.</p>
<section id="feature-importance" class="level4">
<h4 class="anchored" data-anchor-id="feature-importance">Feature Importance</h4>
<p>Knowing a model’s predictive accuracy is critical, but equally important is understanding how those predictions are made. Feature importance offers valuable insight into this process. Sklearn’s random forest model provides feature importance scores via the <code>feature_importance_</code> attributes. Here’s a simple function load these scores into a DataFrame and sort them</p>
<div id="cell-177" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> rf_feat_importance(m, df):</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame({<span class="st">'cols'</span>:df.columns, <span class="st">'imp'</span>:m.feature_importances_}</span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a>                       ).sort_values(<span class="st">'imp'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a>fi <span class="op">=</span> rf_feat_importance(m, xs)</span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a>fi[:<span class="dv">10</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">cols</th>
<th data-quarto-table-cell-role="th">imp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">57</td>
<td>YearMade</td>
<td>0.166375</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">30</td>
<td>Coupler_System</td>
<td>0.113599</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>ProductSize</td>
<td>0.103802</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>fiProductClassDesc</td>
<td>0.078686</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>fiSecondaryDesc</td>
<td>0.054542</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">54</td>
<td>ModelID</td>
<td>0.052919</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">65</td>
<td>saleElapsed</td>
<td>0.050521</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">31</td>
<td>Grouser_Tracks</td>
<td>0.041514</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">12</td>
<td>Enclosure</td>
<td>0.039451</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">32</td>
<td>Hydraulics_Flow</td>
<td>0.035355</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Evaluating the features importances reveals that a few columns significantly contribute to the model’s predictions, most notably, <code>YearMade</code> and <code>ProductSize</code>.</p>
<p>To visualize these importance, plotting them can clarify their relative value:</p>
<div id="cell-179" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_fi(fi):</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> fi.plot(<span class="st">'cols'</span>, <span class="st">'imp'</span>, <span class="st">'barh'</span>, figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">7</span>), legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a>plot_fi(fi[:<span class="dv">30</span>])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-79-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="removing-low-importance-variables" class="level4">
<h4 class="anchored" data-anchor-id="removing-low-importance-variables">Removing Low-Importance Variables</h4>
<p>A subset of columns might suffice to maintain accuracy while enhancing simplicity by discarding low-importance variables. Let’s retain only those with an importance score above 0.005:</p>
<div id="cell-182" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>to_keep <span class="op">=</span> fi[fi.imp<span class="op">&gt;</span><span class="fl">0.005</span>].cols</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(to_keep)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>22</code></pre>
</div>
</div>
<p>Retrain the model using this refined feature set:</p>
<div id="cell-184" class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb123"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>xs_imp <span class="op">=</span> xs[to_keep]</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a>valid_xs_imp <span class="op">=</span> valid_xs[to_keep]</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> rf(xs_imp, y)</span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a>m_rmse(m, xs_imp, y), m_rmse(m, valid_xs_imp, valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>(0.180965, 0.231633)</code></pre>
</div>
</div>
<p>The models accuracy remain consistent, yet fewer columns necessitate examination:</p>
<div id="cell-186" class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb125"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(xs.columns), <span class="bu">len</span>(xs_imp.columns)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>(66, 22)</code></pre>
</div>
</div>
<p>Simplifying a model is often the initial step in enhancing it having 78 columns can be overwhelming for deep analysis. Particularly, a learner, more interpretable model is simpler to deploy and manage.</p>
<p>Revisiting the feature importance plot provides clearer insights:</p>
<div id="cell-188" class="cell" data-execution_count="82">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>plot_fi(rf_feat_importance(m, xs_imp))<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-83-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>While interpreting, redundancy may arise as seen with <code>ProductGroup</code> and <code>ProductGroupDesc</code>. Attemping to remove such redundant features can further streamline interpretation.</p>
</section>
<section id="removing-redundant-variables" class="level4">
<h4 class="anchored" data-anchor-id="removing-redundant-variables">Removing Redundant Variables</h4>
<p>We’ll begin by clustering columns to identify pairs that are closely aligned often suggesting redundancy:</p>
<div id="cell-192" class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>cluster_columns(xs_imp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-84-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The chart generated from clustering will reveal which columns were merged early on. Notably, pairs like <code>ProductGroup</code> with <code>ProductGroupDesc</code>, <code>saleYear</code> with <code>saleElapsed</code>, and <code>fiModelDesc</code> with <code>fiBaseModel</code> are likely correlated to the point of redundancy.</p>
<p>Next, we will attempt to simplify the model by removing these related features. We begin by defining a function to quickly train a random forest and capture the out-of-bag(OOB) score. This score, ranging from 1.0 for perfection to near-zero, provides a relative comparison metric as we remove redundant columns:</p>
<div id="cell-194" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb129"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_oob(df):</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">40</span>, min_samples_leaf<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>        max_samples<span class="op">=</span><span class="dv">50000</span>, max_features<span class="op">=</span><span class="fl">0.5</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>, oob_score<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a>    m.fit(df, y)</span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> m.oob_score_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>First, we’ll confirm our baseline score with all columns:</p>
<div id="cell-196" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>get_oob(xs_imp)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>0.8760739540611289</code></pre>
</div>
</div>
<p>Next, test the impact of removing each potentially redundant variable individually:</p>
<div id="cell-198" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>{c:get_oob(xs_imp.drop(c, axis<span class="op">=</span><span class="dv">1</span>)) <span class="cf">for</span> c <span class="kw">in</span> (</span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'saleYear'</span>, <span class="st">'saleElapsed'</span>, <span class="st">'ProductGroupDesc'</span>,<span class="st">'ProductGroup'</span>,</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'fiModelDesc'</span>, <span class="st">'fiBaseModel'</span>,</span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Hydraulics_Flow'</span>,<span class="st">'Grouser_Tracks'</span>, <span class="st">'Coupler_System'</span>)}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>{'saleYear': 0.8742959821922331,
 'saleElapsed': 0.8698149904307536,
 'ProductGroupDesc': 0.8755334280543031,
 'ProductGroup': 0.8745495772129529,
 'fiModelDesc': 0.8743458666758965,
 'fiBaseModel': 0.8748827464781819,
 'Hydraulics_Flow': 0.8762012623754625,
 'Grouser_Tracks': 0.8755826405754699,
 'Coupler_System': 0.8758570604637711}</code></pre>
</div>
</div>
<p>We’ll also explore the effect of dropping one columns from each identified pair:</p>
<div id="cell-200" class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>to_drop <span class="op">=</span> [<span class="st">'saleYear'</span>, <span class="st">'ProductGroupDesc'</span>, <span class="st">'fiBaseModel'</span>, <span class="st">'Grouser_Tracks'</span>]</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>get_oob(xs_imp.drop(to_drop, axis<span class="op">=</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>0.8743053306321846</code></pre>
</div>
</div>
<p>Encouragingly, the model’s performance remains largely unchanged. We will now finalize this reduce dataset:</p>
<div id="cell-202" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>xs_final <span class="op">=</span> xs_imp.drop(to_drop, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>valid_xs_final <span class="op">=</span> valid_xs_imp.drop(to_drop, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb136-3"><a href="#cb136-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb136-4"><a href="#cb136-4" aria-hidden="true" tabindex="-1"></a>save_pickle(path<span class="op">/</span><span class="st">'xs_final.pkl'</span>, xs_final)</span>
<span id="cb136-5"><a href="#cb136-5" aria-hidden="true" tabindex="-1"></a>save_pickle(path<span class="op">/</span><span class="st">'valid_xs_final.pkl'</span>, valid_xs_final)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For later retrieval, you can load these condensed datasets with:</p>
<div id="cell-204" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>xs_final <span class="op">=</span> load_pickle(path<span class="op">/</span><span class="st">'xs_final.pkl'</span>)</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>valid_xs_final <span class="op">=</span> load_pickle(path<span class="op">/</span><span class="st">'valid_xs_final.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s verify that the RMSE remains consistent after this reduction:</p>
<div id="cell-206" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> rf(xs_final, y)</span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>m_rmse(m, xs_final, y), m_rmse(m, valid_xs_final, valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>(0.182663, 0.231313)</code></pre>
</div>
</div>
<p>By concentrating on key variables and eliminating redundancies, we’ve streamlined our model significantly. Now, let’s further explore how these influential variables affect predictions using partial dependence plots.</p>
</section>
<section id="partial-dependence" class="level4">
<h4 class="anchored" data-anchor-id="partial-dependence">Partial Dependence</h4>
<p>Alright, let’s get a feel for these predictions. Imagine checking out the menu at a restaurant. Before ordering, you’d want to know what’s popular, right? We do the same thing with our data. For <code>ProductSize</code>, we count how many times each size appears using something like Pandas’ <code>value_counts</code> method and then plot this on a bar chart. Here’s our code in action:</p>
<div id="cell-210" class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> valid_xs_final[<span class="st">'ProductSize'</span>].value_counts(sort<span class="op">=</span><span class="va">False</span>).plot.barh()</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>c <span class="op">=</span> to.classes[<span class="st">'ProductSize'</span>]</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>plt.yticks(<span class="bu">range</span>(<span class="bu">len</span>(c)), c)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-92-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Turns out, the biggest “dish” on our menu is labeled <code>Compact</code> but look at #na#, fastai’s way of showing missing values. No big surprise there!</p>
<p>What about YearMade? This time, instead of a bar chart, we whip out a histogram.</p>
<div id="cell-212" class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> valid_xs_final[<span class="st">'YearMade'</span>].hist()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-93-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Apart from 1950, which we used as placeholder for unknown years, most machines were crafted post-1990. Vintage anyone?</p>
<p>Partial dependence plots help us see what would happen to the sale price if one feature changed while everything else stayed the same.</p>
<p>For YearMade, we can’t just average sale prices by year because many things change over time. Instead, we replace every year value with a single year, like 1950, and calculate the average predicted sale price. We repeat this for each year, up to 2011, to see how YearMade alone affects price.</p>
<p>Then, we plot the results:</p>
<div id="cell-214" class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> PartialDependenceDisplay</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>PartialDependenceDisplay.from_estimator(m, valid_xs_final, [<span class="st">'YearMade'</span>, <span class="st">'ProductSize'</span>],</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a>                                        grid_resolution<span class="op">=</span><span class="dv">20</span>, ax<span class="op">=</span>ax)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-94-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>For YearMade, after 1990, there’s a clear pattern: prices rise as the year increase. This make sense because older items depreciate.</p>
<p>The plot for ProductSize show that the group with missing values has the lowest prices. Understanding why these values are missing is crucial, as sometimes they can be good predictors, or they could indicate an issue like data leakage</p>
</section>
<section id="data-leakage" class="level4">
<h4 class="anchored" data-anchor-id="data-leakage">Data Leakage</h4>
<p>In the world of data mining, there’s a tricky issue known as data leakage, described in detail by Shachar Kaufman, Saharon Rosset, and Claudia Perlich in their paper, <a href="https://dl.acm.org/doi/10.1145/2020408.2020496">Leakage in Data Mining: Formulation, Detection, and Avoidance.</a> They define it as the unintentional introduction of information about the target of a data mining problem that shouldn’t be available to mine from. To put it simply, it’s like saying ‘it rains on rainy days,’ where the model mistakenly uses the target itself as an input.</p>
<p>Data leakage can be subtle, appearing in various forms, and one such form is through missing values. Here are the straightforward steps to spot data leakage:</p>
<ul>
<li>Assess whether your model’s accuracy seems too perfect. If it feels too good to be true, leakage might be playing a part.</li>
<li>Evaluate the significant predictors. If they don’t add up in a practical sense, then something might be off.</li>
<li>Analyze the partial dependence plots. If they yield nonsensical results, you could be facing a leakage issue.</li>
</ul>
<p>Additionally, tools like tree interpreters can aid in understanding which factors are influencing specific predictions.</p>
<p>Avoiding data leakage demands meticulous attention through all phases of data handling—from collection to preparation. The key is adopting a “learn-now, predict-later” approach, ensuring that models are built without any preview of the answers.</p>
</section>
<section id="tree-interpreter" class="level4">
<h4 class="anchored" data-anchor-id="tree-interpreter">Tree Interpreter</h4>
<p>Before we go in please make sure you’re already have <code>treeinterpreter</code> and <code>waterfallcharts</code> installed if not run this in your terminal</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install treeinterpreter</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install waterfallcharts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>At the start of this section, we said that we wanted to be able to answer five questions:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>How confident are we in our predictions using particular row of data?</li>
<li>For predicting with a particular row of data, what were the most important factors, and how did they influence that predictions?</li>
<li>Which columns are the strongest predictors, which can we ignore?</li>
<li>Which columns are effectively redundant with each other, for purpose of prediction?</li>
<li>How do predictions vary, as we vary these columns?</li>
</ul>
</div>
</div>
<p>We’ve addressed four of these, leaving only the second question. To tackle this, we’ll use the <code>treeinterpreter</code> library, along with the <code>waterfallcharts</code> library for visualization.</p>
<div id="cell-220" class="cell" data-execution_count="94">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> treeinterpreter <span class="im">import</span> treeinterpreter</span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> waterfall_chart <span class="im">import</span> plot <span class="im">as</span> waterfall</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>While we’ve computed feature importances across entire random forest, we can apply a similar concept to a single row of data. This approach examines the contribution of each variable to improving the model at each branch of every tree, then sums these contributions per variables for a specific data point.</p>
<p>For example, if we’re analyzing a particular auction item predicted to be expensive, we can understand why by examining that single row of data. We’ll process it through each decision tree, observing the split used at each point and calculating the increase or decrease in addition compared to the parent node. This process is repeated for every tree, summing up the total change in importance by split variable.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For example, if you’re predicting house prices:</p>
<ul>
<li>The bias might be the average house price in your dataset.</li>
<li>A positive contribution from the “number of bedrooms” feature would indicate that having more bedrooms increased the predicted price.</li>
<li>A negative contribution from the “distance from city center” feature might indicate that being further from the city center decreased the predicted price.</li>
</ul>
</div>
</div>
<p>Let’s select the first few rows of our validation set:</p>
<div id="cell-222" class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>row <span class="op">=</span> valid_xs_final.iloc[:<span class="dv">5</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then use <code>treeinterpreter</code>:</p>
<div id="cell-224" class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a>prediction,bias,contributions <span class="op">=</span> treeinterpreter.predict(m, row.values)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, <code>prediction</code> is the random forest’s prediction, <code>bias</code> is the prediction based on the mean of the dependent variable, and <code>contributions</code> shows how each feature (independent variable) in your input data contributed to moving the prediction away from the bias. The sum of <code>contributions</code> plus <code>bias</code> equals the <code>prediction</code> for each row</p>
<div id="cell-226" class="cell" data-execution_count="97">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>prediction[<span class="dv">0</span>], bias[<span class="dv">0</span>], contributions[<span class="dv">0</span>].<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="97">
<pre><code>(array([10.06313964]), 10.104746057831763, -0.04160642242374439)</code></pre>
</div>
</div>
<p>To visualize the contributions clearly, we can use waterfall plot:</p>
<div id="cell-228" class="cell" data-execution_count="98">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>waterfall(valid_xs_final.columns, contributions[<span class="dv">0</span>], threshold<span class="op">=</span><span class="fl">0.08</span>,</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>          rotation_value<span class="op">=</span><span class="dv">45</span>,formatting<span class="op">=</span><span class="st">'</span><span class="sc">{:,.3f}</span><span class="st">'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-99-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This plot demonstrates how positive and negative contributes from all independent variables sum up to create the final prediction, show in the rightmost column labeled <code>net</code>.</p>
<p>This type of information is particularly valuable in production environments, rather than during model development. It can provide users of your data product with insightful information about the underlying reasoning behind the predictions.</p>
<p>Having explored these classic machine learning techniques, we’re now ready to see how deep learning can contribute to solving this problem</p>
</section>
</section>
</section>
<section id="extrapolation-and-neuron-networks" class="level2">
<h2 class="anchored" data-anchor-id="extrapolation-and-neuron-networks">Extrapolation and Neuron Networks</h2>
<p>Random forests, like all machine learning or deep learning algorithms, don’t always generalize well to new data. Lets explore this issue, particularly focusing on the extrapolation problem that random forests face.</p>
<section id="the-extrapolation-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-extrapolation-problem">The Extrapolation Problem</h3>
<p>Consider a simple task: making prediction from 40 data points showing a slightly noisy linear relationship. We’ll create this data and visualize it:</p>
<div id="cell-234" class="cell" data-execution_count="99">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>x_lin <span class="op">=</span> torch.linspace(<span class="dv">0</span>,<span class="dv">20</span>, steps<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>y_lin <span class="op">=</span> x_lin <span class="op">+</span> torch.randn_like(x_lin)</span>
<span id="cb150-4"><a href="#cb150-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_lin, y_lin)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-100-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We need to reshape our data for sklearn, which expect a matrix of independent variables:</p>
<div id="cell-236" class="cell" data-execution_count="100">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>xs_lin <span class="op">=</span> x_lin.unsqueeze(<span class="dv">1</span>)</span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>x_lin.shape,xs_lin.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="100">
<pre><code>(torch.Size([40]), torch.Size([40, 1]))</code></pre>
</div>
</div>
<div id="cell-237" class="cell" data-execution_count="101">
<div class="sourceCode cell-code" id="cb153"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>x_lin[:,<span class="va">None</span>].shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="101">
<pre><code>torch.Size([40, 1])</code></pre>
</div>
</div>
<p>Now, let’s create a random forest using the first 30 rows for training:</p>
<div id="cell-239" class="cell" data-execution_count="102">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>m_lin <span class="op">=</span> RandomForestRegressor().fit(xs_lin[:<span class="dv">30</span>],y_lin[:<span class="dv">30</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We’ll test the model on the full dataset and visualize the results:</p>
<div id="cell-241" class="cell" data-execution_count="103">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_lin, y_lin, <span class="dv">20</span>)</span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_lin, m_lin.predict(xs_lin), color<span class="op">=</span><span class="st">'red'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-104-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Here’s where we encounter a significant issue: our predictions outside the training data domain are consistently too low. This happens because a random forest average value of the rows in a leaf. Consequently, a random forest can’t predict values outside the rage of its training data.</p>
<p>This limitation is particularly problematic for data with time-based trends, like inflation, where future predictions are needed. Your predictions will systematically be too low.</p>
<p>The problem isn’t limited to time variables, though. Random forest struggle to extrapolate beyond the types of data they’ve seen in a more general sense. That’s wy it’s crucial to ensure our validation set doesn’t contain out-of-domain data</p>
</section>
<section id="finding-out-of-domain-data" class="level3">
<h3 class="anchored" data-anchor-id="finding-out-of-domain-data">Finding Out-of-Domain Data</h3>
<p>Identifying whether your test set is distributed differently from your training data can be challenging. Interestingly, we can use a random forest to help us with this task. Here’s how:</p>
<p>Instead of predicting our actual dependent variable, we’ll try to predict whether a row belongs to the validation set or the training set. Let’s combine our training and validation sets, create a new dependent variable representing the dataset origin, and build a random forest:</p>
<div id="cell-245" class="cell" data-execution_count="104">
<div class="sourceCode cell-code" id="cb157"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a>df_dom <span class="op">=</span> pd.concat([xs_final, valid_xs_final])</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a>is_valid <span class="op">=</span> np.array([<span class="dv">0</span>]<span class="op">*</span><span class="bu">len</span>(xs_final) <span class="op">+</span> [<span class="dv">1</span>]<span class="op">*</span><span class="bu">len</span>(valid_xs_final))</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> rf(df_dom, is_valid)</span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a>rf_feat_importance(m, df_dom)[:<span class="dv">6</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="104">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">cols</th>
<th data-quarto-table-cell-role="th">imp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>saleElapsed</td>
<td>0.910266</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">11</td>
<td>SalesID</td>
<td>0.073707</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">14</td>
<td>MachineID</td>
<td>0.012246</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">0</td>
<td>YearMade</td>
<td>0.000813</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9</td>
<td>fiModelDesc</td>
<td>0.000535</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>ModelID</td>
<td>0.000471</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>This reveals three columns that differ significantly between the sets: <code>saleElapsed</code>, <code>SalesID</code> and <code>MachineID</code>. <code>saleElapsed</code> directly encoded the date, while <code>SalesID</code> and <code>MachineID</code> likely represent incrementing identifiers over time.</p>
<p>Let’s compare the RMSE of our original model with versions that exclude these columns:</p>
<div id="cell-247" class="cell" data-execution_count="105">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> rf(xs_final, y)</span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'orig'</span>, m_rmse(m, valid_xs_final, valid_y))</span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb158-4"><a href="#cb158-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> c <span class="kw">in</span> (<span class="st">'SalesID'</span>,<span class="st">'saleElapsed'</span>,<span class="st">'MachineID'</span>):</span>
<span id="cb158-5"><a href="#cb158-5" aria-hidden="true" tabindex="-1"></a>    m <span class="op">=</span> rf(xs_final.drop(c,axis<span class="op">=</span><span class="dv">1</span>), y)</span>
<span id="cb158-6"><a href="#cb158-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(c, m_rmse(m, valid_xs_final.drop(c,axis<span class="op">=</span><span class="dv">1</span>), valid_y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>orig 0.231001
SalesID 0.230214
saleElapsed 0.235865
MachineID 0.231447</code></pre>
</div>
</div>
<p>It appears that we can remove SalesID and MachineID without losing accuracy:</p>
<div id="cell-249" class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>time_vars <span class="op">=</span> [<span class="st">'SalesID'</span>,<span class="st">'MachineID'</span>]</span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a>xs_final_time <span class="op">=</span> xs_final.drop(time_vars, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb160-3"><a href="#cb160-3" aria-hidden="true" tabindex="-1"></a>valid_xs_time <span class="op">=</span> valid_xs_final.drop(time_vars, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb160-4"><a href="#cb160-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb160-5"><a href="#cb160-5" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> rf(xs_final_time, y)</span>
<span id="cb160-6"><a href="#cb160-6" aria-hidden="true" tabindex="-1"></a>m_rmse(m, valid_xs_time, valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="106">
<pre><code>0.228264</code></pre>
</div>
</div>
<p>Removing these variables slightlyy improves the model’s accuracy and should make it more resilient over time, easier to maintain, and understand.</p>
<p>Sometimes, using only recent data can help. Let’s try using data from the most recent years:</p>
<div id="cell-251" class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>xs[<span class="st">'saleYear'</span>].hist()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-108-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-252" class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb163"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb163-1"><a href="#cb163-1" aria-hidden="true" tabindex="-1"></a>filt <span class="op">=</span> xs[<span class="st">'saleYear'</span>]<span class="op">&gt;</span><span class="dv">2004</span></span>
<span id="cb163-2"><a href="#cb163-2" aria-hidden="true" tabindex="-1"></a>xs_filt <span class="op">=</span> xs_final_time[filt]</span>
<span id="cb163-3"><a href="#cb163-3" aria-hidden="true" tabindex="-1"></a>y_filt <span class="op">=</span> y[filt]</span>
<span id="cb163-4"><a href="#cb163-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-5"><a href="#cb163-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-6"><a href="#cb163-6" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> rf(xs_filt, y_filt)</span>
<span id="cb163-7"><a href="#cb163-7" aria-hidden="true" tabindex="-1"></a>m_rmse(m, xs_filt, y_filt), m_rmse(m, valid_xs_time, valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>(0.176448, 0.228537)</code></pre>
</div>
</div>
<p>This yields a slightly improvement, demonstraitng that using your entire dataset isn’t always the best approach; sometimes subset can perform better.</p>
<p>I recommend building a model with <code>is_valid</code> as the dependent variable for all datasets. This can uncover subtle domain shift issues that might otherwise go unnoticed.</p>
<p>Next, we’ll explore whether using a neural network can further improve our results</p>
</section>
<section id="using-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="using-neural-networks">Using Neural Networks</h3>
<p>To build a neural network model, we’ll follow a similar approach to our random forest setup. First, let’s replicate the steps for creating the TabularPandas object:</p>
<div id="cell-256" class="cell">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>df_nn <span class="op">=</span> pd.read_csv(path<span class="op">/</span><span class="st">'TrainAndValid.csv'</span>, low_memory<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>df_nn[<span class="st">'ProductSize'</span>] <span class="op">=</span> df_nn[<span class="st">'ProductSize'</span>].astype(<span class="st">'category'</span>)</span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a>df_nn[<span class="st">'ProductSize'</span>].cat.set_categories(sizes, ordered<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb165-4"><a href="#cb165-4" aria-hidden="true" tabindex="-1"></a>df_nn[dep_var] <span class="op">=</span> np.log(df_nn[dep_var])</span>
<span id="cb165-5"><a href="#cb165-5" aria-hidden="true" tabindex="-1"></a>df_nn <span class="op">=</span> add_datepart(df_nn, <span class="st">'saledate'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can utilize the column selection from our random forest model for the neural network:</p>
<div id="cell-258" class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>df_nn_final <span class="op">=</span> df_nn[<span class="bu">list</span>(xs_final_time.columns) <span class="op">+</span> [dep_var]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Neural networks handle categorical columns differently than decision trees. Embedding are an effective method for categorical varaibles in neural nets. Fastai determines which columns should be treated as categorical by comparing the number of distinct levels to the <code>max_card</code> parameter. We’ll use 9,000 as our <code>max_card</code> to avoid unnecessarily large embeddings:</p>
<div id="cell-260" class="cell" data-execution_count="111">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>cont_nn,cat_nn <span class="op">=</span> cont_cat_split(df_nn_final, max_card<span class="op">=</span><span class="dv">9000</span>, dep_var<span class="op">=</span>dep_var)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>It’s crucial to ensure that <code>saleElapsed</code> isn’t treated as a categorical variable as we need to predict auction sale prices in the feature. Let’s verify the continuos variable</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As a continuous variable, <code>saleElapsed</code> can capture trends over time. If it were treated as a categorical variable, you’d lose the ability to interpolate or extrapolate between known values, which is crucial for prediction.</p>
<p>When you’re predicting auction sale prices for future dates, you’ll be dealing with ‘saleElapsed’ values that weren’t in your training data. If ‘saleElapsed’ were categorical, your model wouldn’t know how to handle these new values.</p>
</div>
</div>
<div id="cell-262" class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>cont_nn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="112">
<pre><code>['saleElapsed']</code></pre>
</div>
</div>
<p>Now, let’s examine the cardinality of our chhoosen categorical variables:</p>
<div id="cell-264" class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb170"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb170-1"><a href="#cb170-1" aria-hidden="true" tabindex="-1"></a>df_nn_final[cat_nn].nunique()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>YearMade                73
Coupler_System           2
ProductSize              6
fiProductClassDesc      74
fiSecondaryDesc        177
ModelID               5281
Enclosure                6
Hydraulics_Flow          3
fiModelDesc           5059
fiModelDescriptor      140
Hydraulics              12
ProductGroup             6
Drive_System             4
Tire_Size               17
Track_Type               2
dtype: int64</code></pre>
</div>
</div>
<p>We notice two “model” variables with similar high cardicalities, suggesting potential redundancy. To reduce the embedding matrix size. Let’s assess the impact of removing one of these model columns on our random forest:</p>
<div id="cell-266" class="cell" data-execution_count="114">
<div class="sourceCode cell-code" id="cb172"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb172-1"><a href="#cb172-1" aria-hidden="true" tabindex="-1"></a>xs_filt2 <span class="op">=</span> xs_filt.drop(<span class="st">'fiModelDescriptor'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb172-2"><a href="#cb172-2" aria-hidden="true" tabindex="-1"></a>valid_xs_time2 <span class="op">=</span> valid_xs_time.drop(<span class="st">'fiModelDescriptor'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb172-3"><a href="#cb172-3" aria-hidden="true" tabindex="-1"></a>m2 <span class="op">=</span> rf(xs_filt2, y_filt)</span>
<span id="cb172-4"><a href="#cb172-4" aria-hidden="true" tabindex="-1"></a>m_rmse(m2, xs_filt2, y_filt), m_rmse(m2, valid_xs_time2, valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="114">
<pre><code>(0.178386, 0.229505)</code></pre>
</div>
</div>
<p>given the minimal impact, We’ll remove <code>fiModelDescriptor</code> from our neural network predictors:</p>
<div id="cell-268" class="cell" data-execution_count="115">
<div class="sourceCode cell-code" id="cb174"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb174-1"><a href="#cb174-1" aria-hidden="true" tabindex="-1"></a>cat_nn.remove(<span class="st">'fiModelDescriptor'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>When creating our <code>TabularPandas</code> object for the neuronn network, we need to add normalization, which is crucial for neural networks but unnecessary for random forests:</p>
<div id="cell-270" class="cell" data-execution_count="116">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>procs_nn <span class="op">=</span> [Categorify, FillMissing, Normalize]</span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>to_nn <span class="op">=</span> TabularPandas(df_nn_final, procs_nn, cat_nn, cont_nn,</span>
<span id="cb175-3"><a href="#cb175-3" aria-hidden="true" tabindex="-1"></a>                      splits<span class="op">=</span>splits, y_names<span class="op">=</span>dep_var)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Since tabular models and data generally don’t require much GPU RAM, we can use larger batch sizes:</p>
<div id="cell-272" class="cell" data-execution_count="117">
<div class="sourceCode cell-code" id="cb176"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb176-1"><a href="#cb176-1" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> to_nn.dataloaders(<span class="dv">1024</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For regression models, it’s advisable to set y_range. Let’s find the min and mux of our dependent variable:</p>
<div id="cell-274" class="cell" data-execution_count="118">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> to_nn.train.y</span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a>y.<span class="bu">min</span>(),y.<span class="bu">max</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="118">
<pre><code>(8.465899467468262, 11.863582611083984)</code></pre>
</div>
</div>
<p>Now we can create the <code>Learner</code> for our tabular model. We’ll use MSE as the loss function and increase the default layer sizes to 500 and 250 for our large dataset:</p>
<div id="cell-276" class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> tabular_learner(dls, y_range<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">12</span>), layers<span class="op">=</span>[<span class="dv">500</span>,<span class="dv">250</span>],</span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a>                        n_out<span class="op">=</span><span class="dv">1</span>, loss_func<span class="op">=</span>F.mse_loss)</span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>learn.lr_find()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="119">
<pre><code>SuggestedLRs(valley=0.00013182566908653826)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="index_files/figure-html/cell-120-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We’ll train with <code>fit_one_cycle</code> for a few epochs:</p>
<div id="cell-278" class="cell" data-execution_count="120">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">5</span>, <span class="fl">1e-2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.061921</td>
<td>0.067224</td>
<td>00:05</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.051130</td>
<td>0.056330</td>
<td>00:04</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.046388</td>
<td>0.054012</td>
<td>00:03</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.041853</td>
<td>0.054157</td>
<td>00:03</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.040173</td>
<td>0.052207</td>
<td>00:03</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Let’s compare the result to our earlier random forest using the <code>r_mse</code> function:</p>
<div id="cell-280" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>preds,targs <span class="op">=</span> learn.get_preds()</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a>r_mse(preds,targs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="121">
<pre><code>0.228488</code></pre>
</div>
</div>
<p>The neural network performs better than the random forest, although it take longer to train and requires more carful hyprerparameter tuning</p>
<p>We’ll save our model for future use:</p>
<div id="cell-282" class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb184"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a>learn.save(<span class="st">'nn'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="122">
<pre><code>Path('models/nn.pth')</code></pre>
</div>
</div>
<p>To further improve generalization, we can use ensemble learning, which envolves averaging predictions from several models.</p>
</section>
</section>
<section id="ensembling" class="level2">
<h2 class="anchored" data-anchor-id="ensembling">Ensembling</h2>
<p>The cuccess of random forests is rooted in the principle that while individual trees have errors, these erros are not correlated. With enough trees, the average of these errors should approach zero. We can apply similar reasoning to combine predictions from different algorithms.</p>
<p>In our case, we have two distinct models: a random forest and a neural network. Their different approaches likly result in different types of errors. Therefore, averageing their predictions could potentially outperform either model individually.</p>
<p>It’s worth nothing that a random forest is itselft an ensemble, By combining it with a neural network, we’re creating an ensemble of ensembles! While ensembling may not revolutionize your modeling process, it can provide a welcome boost to your exiting model.</p>
<p>One small challenge we face is the different output types from our Pytorch and sklearn models. Pytorch gives a rank-2 tensor (a column matrix), while sklearn produces a rank-1 array (a vector). We can address this using <code>squeeze</code> to remove unit axes and <code>to_np</code> to convert to Numpy array</p>
<div id="cell-286" class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb186"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb186-1"><a href="#cb186-1" aria-hidden="true" tabindex="-1"></a>rf_preds <span class="op">=</span> m.predict(valid_xs_time)</span>
<span id="cb186-2"><a href="#cb186-2" aria-hidden="true" tabindex="-1"></a>ens_preds <span class="op">=</span> (to_np(preds.squeeze()) <span class="op">+</span> rf_preds) <span class="op">/</span><span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This ensemble approach yield better result than either model individually:</p>
<div id="cell-288" class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a>r_mse(ens_preds,valid_y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="124">
<pre><code>0.222895</code></pre>
</div>
</div>
</section>
<section id="boosting" class="level2">
<h2 class="anchored" data-anchor-id="boosting">Boosting</h2>
<p>While our previous ensembling approach used bagging (combination many models trained on different data subsets by averaging), another important technique is boosting, where models are added instead of averaged.</p>
<p>Boosting works as follow:</p>
<ol type="1">
<li>Train a small, underfitting model on you dataset.</li>
<li>Calculate this model predictions for the training set.</li>
<li>Subtract these predictions from the actual targets to get the “residuals”(the error for each training point).</li>
<li>Return to step 1, but use the residuals as the new training targets.</li>
<li>Repeat this process until reaching a stopping criterion(e.g., maximum number of trees or worsening validation set error).</li>
</ol>
<p>In this approach, each new tree attempts to fit the combined error of all previous trees. As we continually create new residuals by subtracting each new tree’s predictions from the previous residuals, these residuals progressively decrease.</p>
<p>To make predictions with a boosted tree ensemble, we calculate predictions from each tree and sum them. This approach has many variations and names, including Gradient Boosting Machines (GBMs) and Gradient Boosted Decision Trees (GBDTs). XGBoost is currently the most popular implementation.</p>
<p>Unlike random forests, boosting can lead to overfitting. In random forests, adding more trees doesn’t cause overfitting because each tree is independent. However, in a boosted ensemble, more trees continuously improve the training error, potentially leading to overfitting on the validation set.</p>
</section>
<section id="key-takeaway" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaway">Key takeaway</h2>
<p>We have discussed two approaches to tabular modeling: decision tree ensembles and neural networks. We’ve also mentioned two different decision tree ensembles: random forests, and gradient boosting machines. Each is very effective, but each also has compromises:</p>
<ul>
<li><em>Random forests</em> are the easiest to train, because they are extremely resilient to hyperparameter choices and require very little preprocessing. They are very fast to train, and should not overfit if you have enough trees. But they can be a little less accurate, especially if extrapolation is required, such as predicting future time periods.</li>
<li><em>Gradient boosting</em> machines in theory are just as fast to train as random forests, but in practice you will have to try lots of different hyperparameters. They can overfit, but they are often a little more accurate than random forests.</li>
<li><em>Neural networks</em> take the longest time to train, and require extra preprocessing, such as normalization; this normalization needs to be used at inference time as well. They can provide great results and extrapolate well, but only if you are careful with your hyperparameters and take care to avoid overfitting.</li>
</ul>
<p>We suggest starting your analysis with a random forest. This will give you a strong baseline, and you can be confident that it’s a reasonable starting point. You can then use that model for feature selection and partial dependence analysis, to get a better understanding of your data.</p>
<p>From that foundation, you can try neural nets and GBMs, and if they give you significantly better results on your validation set in a reasonable amount of time, you can use them. If decision tree ensembles are working well for you, try adding the embeddings for the categorical variables to the data, and see if that helps your decision trees learn better.</p>
<p>Alright guys, it’s been a long post huh? thanks for reading all of those, catch you on the flip side, and I’ll see you… next time!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/buidai123\.github\.io\/blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="buidai123/buidai123.github.io.comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Copyright 2024, Bui Huu Dai
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>